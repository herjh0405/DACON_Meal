{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LH_LightGBM.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGMqHrKjNQ8J6bgy/r+wnl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/herjh0405/DACON_Meal/blob/master/LH_LightGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHbiFM-wF1OV"
      },
      "source": [
        "# !pip install pycaret\n",
        "# !pip install kaggler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGawgXqoGQXz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpYUzBk6GR77"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "np.random.seed(0)\n",
        "\n",
        "from pycaret.regression import *\n",
        "from kaggler.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import os, re\n",
        "import glob\n",
        "import calendar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56K2Jp9ZGZmG"
      },
      "source": [
        "# 한글 폰트 사용\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import os\n",
        "\n",
        "def change_matplotlib_font(font_download_url):\n",
        "    FONT_PATH = 'MY_FONT'\n",
        "    \n",
        "    font_download_cmd = f\"wget {font_download_url} -O {FONT_PATH}.zip\"\n",
        "    unzip_cmd = f\"unzip -o {FONT_PATH}.zip -d {FONT_PATH}\"\n",
        "    os.system(font_download_cmd)\n",
        "    os.system(unzip_cmd)\n",
        "    \n",
        "    font_files = fm.findSystemFonts(fontpaths=FONT_PATH)\n",
        "    for font_file in font_files:\n",
        "        fm.fontManager.addfont(font_file)\n",
        "\n",
        "    font_name = fm.FontProperties(fname=font_files[0]).get_name()\n",
        "    matplotlib.rc('font', family=font_name)\n",
        "    print(\"font family: \", plt.rcParams['font.family'])\n",
        "\n",
        "font_download_url = \"https://fonts.google.com/download?family=Noto%20Sans%20KR\"\n",
        "change_matplotlib_font(font_download_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alJVOVSIGbW3"
      },
      "source": [
        "path = '/content/drive/MyDrive/구내식당/water/'\n",
        "train = pd.read_csv(path+'train.csv')\n",
        "test = pd.read_csv(path+'test.csv')\n",
        "holiday = pd.read_csv(path+'holidays.csv', index_col=0)\n",
        "corona = pd.read_csv(path+'corona_data.csv')\n",
        "\n",
        "df = pd.concat([train.iloc[:, :-2], test])\n",
        "target_df = train.iloc[:, -2:]\n",
        "df.columns = ['일자', '요일', '정원','휴가자', '출장자', '야근자',\\\n",
        "                 '재택근무자', '조식', '중식', '석식']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qBVVw5tHtmJ"
      },
      "source": [
        "dust_dir = os.path.join(path, '미세먼지_일별')\n",
        "wdata_dir = os.path.join(path, '날씨_시간별')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb7x5xhGHuuA"
      },
      "source": [
        "w_attrs = ['강수', '기온', '습도', '강수형태']\n",
        "w_years = os.listdir(wdata_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUHg4qXcHyYG"
      },
      "source": [
        "def get_wdata(data_path, dtype='num'):\n",
        "  datetime_list = []\n",
        "  value_list_12 = []\n",
        "  value_list_18 = []\n",
        "  curr_mon = ''\n",
        "\n",
        "  with open(data_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for i, line in enumerate(lines):\n",
        "      if line.strip() == '':\n",
        "        break\n",
        "      row_data = line.strip().split(',')\n",
        "      row_data = [elem.strip() for elem in row_data]\n",
        "      if i == 0:\n",
        "        curr_mon = row_data[-1].split()[-1][:-2]\n",
        "        continue\n",
        "      if len(row_data) == 1:\n",
        "        curr_mon = row_data[-1].split()[-1][:-2]\n",
        "        continue\n",
        "      r_day, r_hour, r_value = row_data\n",
        "      if r_hour in [\"1200\", \"1800\"]: # 점심 12시, 저녁 6시 기준으로 처리\n",
        "        if r_hour == \"1200\":\n",
        "          datetime_list.append(curr_mon[:4]+'-'+curr_mon[4:]+'-'+str('%02d'%int(r_day)))\n",
        "\n",
        "        if dtype == 'num':\n",
        "          if r_hour == \"1200\":\n",
        "            value_list_12.append(float(r_value))\n",
        "          else:\n",
        "            value_list_18.append(float(r_value))\n",
        "        else:\n",
        "          if r_hour == \"1200\":\n",
        "            value_list_12.append(str(round(float(r_value))))\n",
        "          else:\n",
        "            value_list_18.append(str(round(float(r_value))))\n",
        "          \n",
        "\n",
        "  return datetime_list, value_list_12, value_list_18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WYQYVGEHz2A"
      },
      "source": [
        "# 강수, 기온, 습도, 강수형태 데이터\n",
        "w_data_rain_12 = []\n",
        "w_data_temp_12 = []\n",
        "w_data_hum_12 = []\n",
        "w_data_rtype_12 = []\n",
        "w_data_rain_18 = []\n",
        "w_data_temp_18 = []\n",
        "w_data_hum_18 = []\n",
        "w_data_rtype_18 = []\n",
        "w_datetime = []\n",
        "\n",
        "for year in w_years:\n",
        "  w_subdir = os.path.join(wdata_dir, year)\n",
        "  file_names = os.listdir(w_subdir)\n",
        "  file_name = \"\"\n",
        "  if year != '2021':\n",
        "    file_name = f'{year}01_{year}12.csv'\n",
        "  else:\n",
        "    file_name = f'{year}01_{year}04.csv'\n",
        "  file_path_rain = os.path.join(w_subdir, '충무공동_강수_'+file_name)\n",
        "  file_path_temp = os.path.join(w_subdir, '충무공동_기온_'+file_name)\n",
        "  file_path_hum = os.path.join(w_subdir, '충무공동_습도_'+file_name)\n",
        "  file_path_rtype = os.path.join(w_subdir, '충무공동_강수형태_'+file_name)\n",
        "\n",
        "  datetime_list_rain, value_list_rain_12, value_list_rain_18 = get_wdata(file_path_rain, dtype='num') # 강수 데이터\n",
        "  datetime_list_temp, value_list_temp_12, value_list_temp_18 = get_wdata(file_path_temp, dtype='num') # 기온 데이터\n",
        "  datetime_list_hum, value_list_hum_12, value_list_hum_18 = get_wdata(file_path_hum, dtype='num') # 습도 데이터\n",
        "  datetime_list_rtype, value_list_rtype_12, value_list_rtype_18 = get_wdata(file_path_rtype, dtype='cat') # 강수형태 데이터\n",
        "  \n",
        "  w_datetime   += datetime_list_rain\n",
        "  w_data_rain_12  += value_list_rain_12\n",
        "  w_data_temp_12  += value_list_temp_12\n",
        "  w_data_hum_12   += value_list_hum_12\n",
        "  w_data_rtype_12 += value_list_rtype_12\n",
        "  w_data_rain_18  += value_list_rain_18\n",
        "  w_data_temp_18  += value_list_temp_18\n",
        "  w_data_hum_18   += value_list_hum_18\n",
        "  w_data_rtype_18 += value_list_rtype_18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yQ7qAB2H088"
      },
      "source": [
        "w_df = pd.DataFrame({'일자':pd.Series(w_datetime, dtype='str'),\n",
        "                   'rain_lunch':pd.Series(w_data_rain_12, dtype='float'),\n",
        "                   'temp_lunch':pd.Series(w_data_temp_12, dtype='float'),\n",
        "                   'hum_lunch':pd.Series(w_data_hum_12, dtype='float'),\n",
        "                   'rain_type_lunch':pd.Series(w_data_rtype_12, dtype='str'),\n",
        "                   'rain_dinner':pd.Series(w_data_rain_18, dtype='float'),\n",
        "                   'temp_dinner':pd.Series(w_data_temp_18, dtype='float'),\n",
        "                   'hum_dinner':pd.Series(w_data_hum_18, dtype='float'),\n",
        "                   'rain_type_dinner':pd.Series(w_data_rtype_18, dtype='str')})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppA8WoaZH1d4"
      },
      "source": [
        "# 불쾌지수 컬럼 추가\n",
        "# https://dacon.io/competitions/official/235736/codeshare/2753?page=1&dtype=recent\n",
        "w_df['discomfort_index_lunch'] = 1.8*w_df['temp_lunch'] - 0.55*(1-w_df['hum_lunch']/100)*(1.8*w_df['temp_lunch']-26) + 32\n",
        "w_df['discomfort_index_dinner'] = 1.8*w_df['temp_dinner'] - 0.55*(1-w_df['hum_dinner']/100)*(1.8*w_df['temp_dinner']-26) + 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VOPdw7fH3El"
      },
      "source": [
        "dust_file_paths = glob.glob(os.path.join(dust_dir, '*.xls'))\n",
        "d_datetime = []\n",
        "d_value1 = []\n",
        "d_value2 = []\n",
        "\n",
        "# 시간별 데이터의 경우 미세먼지 측정값 중 빈 값이 있는 경우가 어느 정도 있어서 배제했습니다.\n",
        "for file_path in dust_file_paths:\n",
        "  date_yyyymm = os.path.splitext(os.path.basename(file_path))[0] # yyyymm\n",
        "  date_year = date_yyyymm[:4]\n",
        "  date_mon = date_yyyymm[4:]\n",
        "  dust_df = None\n",
        "\n",
        "  if date_year == '2021':\n",
        "    dust_df = pd.read_excel(file_path, header=[0, 1], skiprows=3)\n",
        "  else:\n",
        "    dust_df = pd.read_excel(file_path, header=[0, 1])\n",
        "  cols = dust_df.columns\n",
        "  date_col = cols[0]\n",
        "  fine_dust_col = cols[1] # 미세먼지\n",
        "  ufine_dust_col = cols[2] # 초미세먼지\n",
        "\n",
        "  # 해당월의 일수 가져오기\n",
        "  days = calendar.monthrange(int(date_year),int(date_mon))[1] \n",
        "  for day in range(1, days+1):\n",
        "    day_1 = '%02d'%day\n",
        "    curr_day_df =  date_year+ '-' + date_mon + '-' + day_1\n",
        "\n",
        "    row_lunch = dust_df[dust_df[cols[0]] == curr_day_df]\n",
        "    row_dinner = dust_df[dust_df[cols[0]] == curr_day_df]\n",
        "    curr_date = date_year+'-'+date_mon+'-'+day_1\n",
        "  \n",
        "    d_datetime.append(curr_date)\n",
        "    d_value1.append(row_lunch[fine_dust_col].values[0])\n",
        "    d_value2.append(row_lunch[ufine_dust_col].values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ-SIBzAH4zk"
      },
      "source": [
        "dust_df = pd.DataFrame({'일자':pd.Series(d_datetime, dtype='str'),\n",
        "                   'fine_dust':pd.Series(d_value1, dtype='float'),\n",
        "                   'ultra_fine_dust':pd.Series(d_value2, dtype='float')})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3hWemuCG0bc"
      },
      "source": [
        "df['재택근무자'] = df['재택근무자'].astype('int')\n",
        "\n",
        "# 날씨, 미세먼지 데이터 추가\n",
        "df = pd.merge(df, dust_df, on='일자')\n",
        "df = pd.merge(df, w_df, on='일자')\n",
        "# train = pd.merge(train, dust_df, on='일자')\n",
        "# train = pd.merge(train, w_df, on='일자')\n",
        "\n",
        "# test = pd.merge(test, dust_df, on='일자')\n",
        "# test = pd.merge(test, w_df, on='일자')\n",
        "\n",
        "df['일자'] = pd.to_datetime(df['일자'])\n",
        "df['년'] = df['일자'].dt.year\n",
        "df['월'] = df['일자'].dt.month\n",
        "df['일'] = df['일자'].dt.day\n",
        "df['월일'] = df['일자'].apply(lambda x : str(x)[5:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R6oeZmRG1R_"
      },
      "source": [
        "holiday['date'] = pd.to_datetime(holiday['date'])\n",
        "df['before_holiday'] = df['일자'].apply(lambda x : 1 if (x+dt.timedelta(1) in holiday['date'].tolist())\\\n",
        "                                      or ((x+dt.timedelta(1)).weekday() == 5) or ((x+dt.timedelta(1)).weekday() == 6) else 0)\n",
        "df['after_holiday'] = df['일자'].apply(lambda x : 1 if (x-dt.timedelta(1) in holiday['date'].tolist())\\\n",
        "                                     or ((x-dt.timedelta(1)).weekday() == 5) or ((x-dt.timedelta(1)).weekday() == 6) else 0)\n",
        "train = pd.concat([df.iloc[:train.shape[0],:], target_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCPPrPtQHGqR"
      },
      "source": [
        "df['요일'] = df['일자'].dt.weekday\n",
        "df['야근_가능'] = df['요일'].apply(lambda x : 1 if (x==2) or (x==4) else 0)\n",
        "df['출근인원'] = df['정원']-(df['휴가자']+df['출장자']+df['재택근무자'])\n",
        "df['휴가비율'] = df['휴가자']/df['정원']\n",
        "df['출장비율'] = df['출장자']/df['정원']\n",
        "df['야근비율'] = df['야근자']/df['출근인원']\n",
        "df['재택비율'] = df['재택근무자']/df['정원']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lDAvk4JIUEt"
      },
      "source": [
        "month_to_season = {1: 3,2: 3,3:0,4:0,5:0,6:1,7:1,8:1,9:2,10:2,11:2,12: 3}\n",
        "df['계절'] = df['월'].apply(lambda x : month_to_season[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AnoQfOUMypD"
      },
      "source": [
        "df['주'] = df['일자'].dt.week\n",
        "df['월_주'] = df['일자'].dt.week%4\n",
        "df['일자'] = pd.to_numeric(df['일자'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk1m40WsIU_U"
      },
      "source": [
        "train = pd.concat([df.iloc[:train.shape[0], :], target_df], axis=1)\n",
        "test = df.iloc[train.shape[0]:, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHl-1DaFJhfU"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "normal_col = ['fine_dust', 'ultra_fine_dust', 'rain_lunch', 'temp_lunch', 'hum_lunch',\n",
        "       'rain_type_lunch', 'discomfort_index_lunch', '출근인원', '주', '일자']\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df[normal_col] = scaler.fit_transform(df[normal_col])\n",
        "\n",
        "lbe = LabelEncoder()\n",
        "df[['년']] = lbe.fit_transform(df[['년']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFzRHGSqJclh"
      },
      "source": [
        "# train_1 = df[['일자', '요일', 'fine_dust', 'ultra_fine_dust', 'rain_lunch', 'temp_lunch', 'hum_lunch',\n",
        "#        'rain_type_lunch', 'discomfort_index_lunch', '년', '월', 'before_holiday', 'after_holiday', '야근_가능', '출근인원',\n",
        "#        '휴가비율', '출장비율', '야근비율', '재택비율', '계절', '주', '월_주']]\n",
        "\n",
        "train_1 = df[['일자', '요일', '월', '년', '휴가비율', '출장비율', '계절', '주', '월_주',\n",
        "              '출근인원', '야근_가능', 'after_holiday', 'discomfort_index_lunch', 'rain_lunch']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ-AHpJBL7-u"
      },
      "source": [
        "y = train['중식계']\n",
        "X = train_1.iloc[:train.shape[0],:]\n",
        "X_tst = train_1.iloc[train.shape[0]:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ae91hulMKZt"
      },
      "source": [
        "from kaggler.model import AutoLGB\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import lightgbm as lgb\n",
        "\n",
        "n_class = 1\n",
        "n_fold = 5\n",
        "cv = StratifiedKFold(n_splits=n_fold)\n",
        "p = np.zeros((X.shape[0], n_class), dtype=float)\n",
        "p_tst = np.zeros((X_tst.shape[0], n_class), dtype=float)\n",
        "n_best = 96\n",
        "# params = {'num_class' : 1}\n",
        "params = {'bagging_freq': 1, 'verbosity': -1, 'seed': 42, 'num_threads': -1, 'feature_pre_filter': False,\\\n",
        "           'num_class': 1, 'objective': 'regression', 'metric': 'l1', 'boosting': 'gbdt', 'bagging_fraction': 0.7000000000000001,\\\n",
        "           'feature_fraction': 0.7000000000000001, 'lambda_l1': 10, 'lambda_l2': 0.1, 'learning_rate': 0.09713575840441935,\\\n",
        "           'max_depth': 6, 'min_child_samples': 10, 'num_leaves': 255}\n",
        "features=X.columns\n",
        "\n",
        "for i_cv, (i_trn, i_val) in enumerate(cv.split(X, y)):\n",
        "    # if i_cv == 0:\n",
        "    #     clf = AutoLGB(objective='regression', metric='mae', params=params,\n",
        "    #                   feature_selection=False, n_est=10000)\n",
        "    #     clf.tune(X.iloc[i_trn], y[i_trn])\n",
        "    #     n_best = clf.n_best\n",
        "    #     features = clf.features\n",
        "    #     params = clf.params\n",
        "    #     print(f'best iteration: {n_best}')\n",
        "    #     print(f'selected features ({len(features)}): {features}')        \n",
        "    #     print(params)\n",
        "    #     clf.fit(X.iloc[i_trn], y[i_trn])\n",
        "    # else:\n",
        "    #     train_data = lgb.Dataset(X[features].iloc[i_trn], label=y[i_trn])\n",
        "    #     clf = lgb.train(params, train_data, n_best, verbose_eval=100)\n",
        "    train_data = lgb.Dataset(X[features].iloc[i_trn], label=y[i_trn])\n",
        "    clf = lgb.train(params, train_data, n_best, verbose_eval=100)\n",
        "    \n",
        "    p[i_val] = clf.predict(X[features].iloc[i_val]).reshape(-1, 1)\n",
        "    p_tst += clf.predict(X_tst[features]).reshape(-1, 1) / n_fold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYhEwCqLS68i"
      },
      "source": [
        "# 기본 column = ['요일', '월', '년', '휴가비율', '출장비율', '계절', '주', '월_주']\n",
        "# CV MAE: 68.747507 - 기본\n",
        "# CV MAE: 65.913536 - +휴일 전후, 일자, 야근_가능\n",
        "# CV MAE: 65.748532 - +휴일 후, 일자, 야근\n",
        "# CV MAE: 65.873269 - +출근 인원\n",
        "# CV MAE: 65.724711 - +불쾌 지수\n",
        "# CV MAE: 65.289932 - +rain_lunch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46gD5wTHRGlo"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "print(f'CV MAE: {mean_absolute_error(y, p):f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnm4uzlnSxO4"
      },
      "source": [
        "def plot_feature_importance(importance,names,model_type):\n",
        "    import seaborn as sns\n",
        "    \n",
        "    feature_importance = np.array(importance)\n",
        "    feature_names = np.array(names)\n",
        "    \n",
        "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
        "    fi_df = pd.DataFrame(data)\n",
        "    \n",
        "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
        "\n",
        "    plt.figure(figsize=(10,8))\n",
        "\n",
        "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
        "\n",
        "    plt.title(model_type + ' Feature Importance')\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.ylabel('Feature Names')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzgS_-o-Vt4v"
      },
      "source": [
        "plot_feature_importance(clf.feature_importance(), X.columns, 'LightGBM')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-zHwlflWCjV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}