{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LH_Final_Code.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"mount_file_id":"1TSTtCz2kIzBwFhsAQvwYkGyS3Kql3LvD","authorship_tag":"ABX9TyMbC85LSfL40re7cLL1xiEr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zd7LfpivX3aG"},"source":["## LH_구내식당_식수인원_예측"]},{"cell_type":"markdown","metadata":{"id":"YqcKCEjqWqSl"},"source":["## Environment"]},{"cell_type":"code","metadata":{"id":"0E9VDTmhVySm"},"source":["!pip install catboost\n","!pip install kaggler\n","!pip install pendulum\n","!pip install flaml\n","!pip install shap"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHSdRVGwV5-f"},"source":["import pandas as pd\n","import numpy as np\n","import datetime as dt\n","import datetime\n","np.random.seed(0)\n","\n","from kaggler.preprocessing import LabelEncoder\n","from sklearn.metrics import roc_auc_score, log_loss\n","\n","from tqdm.notebook import tqdm\n","import os, re\n","import glob\n","import calendar\n","\n","from flaml import AutoML\n","import statsmodels.api as sm\n","import pendulum"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AMv6UaiFWwWq"},"source":["## Load Data"]},{"cell_type":"code","metadata":{"id":"bxfSkfvSV_6W"},"source":["path = '/content/drive/MyDrive/구내식당/water/'\n","train = pd.read_csv(path+'train.csv')\n","test = pd.read_csv(path+'test.csv')\n","holiday = pd.read_csv(path+'holidays_old.csv')\n","\n","df = pd.concat([train.iloc[:, :-2], test])\n","target_df = train.iloc[:, -2:]\n","df.columns = ['일자', '요일', '정원','휴가자', '출장자', '야근자',\\\n","                 '재택근무자', '조식', '중식', '석식']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7fPtL4hrYH8O"},"source":["## Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"OKiSc28OV__o"},"source":["### Menu Feature Preprocessing"]},{"cell_type":"code","metadata":{"id":"GlEwD5HvWACF"},"source":["# Menu-extracting function\n","def extractMenu(array, keywords=[], not_in_keywords={}, comm_not_in=[]):\n","  extractedMenu = []\n","  for menu_nm in array:\n","    for kw in keywords:\n","      if menu_nm.find(kw) > -1:\n","        has_not_in = False\n","        if kw in not_in_keywords:\n","          for sub_kw in not_in_keywords[kw]:\n","            if menu_nm.find(sub_kw) > -1:\n","              has_not_in = True\n","              break\n","        for sub_kw in comm_not_in:\n","            if menu_nm.find(sub_kw) > -1:\n","              has_not_in = True\n","              break\n","\n","        if not has_not_in:\n","          extractedMenu.append(menu_nm)\n","          break\n","  return(extractedMenu)\n","\n","def extractMenu2(array, keywords=[]):\n","  extractedMenu = []\n","  for menu_nm in tot_menu_arr:\n","    for kw in keywords:\n","      if menu_nm.find(kw) > -1:\n","        menu_nm_list = re.split(r'[^\\w]', menu_nm)\n","        for menu_nm_tmp in menu_nm_list:\n","          if menu_nm_tmp.find(kw) + len(kw) == len(menu_nm_tmp): # 끝에 있으면\n","            extractedMenu.append(menu_nm)\n","        break\n","  return(extractedMenu)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VhOYpREKWAEd"},"source":["lunch_menu_data = df['중식']\n","dinner_menu_data = df['석식']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EWX9-97bWAG6"},"source":["tot_menu_arr = []\n","pattern = r\"\\(.*\\)\"\n","for menu_data in [lunch_menu_data, dinner_menu_data]:\n","  for daily_menu in menu_data:\n","    menu_list = daily_menu.strip().split()\n","    menu_list2 = []\n","    for i, menu_nm in enumerate(menu_list):\n","      menu_nm = re.sub(pattern, '', menu_nm)\n","      if menu_nm.strip() in ['', '*']:\n","        continue\n","      if menu_nm[0] == '(' or menu_nm[-1] == ')':\n","        continue\n","      menu_list2.append(menu_nm)\n","    tot_menu_arr += menu_list2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EF2UX1ZiWAJr"},"source":["tot_menu_arr = set(tot_menu_arr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jdM2pXARWAMA"},"source":["len(tot_menu_arr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGod4JY5WAOm"},"source":["# 육류 분류\n","# 소고기\n","# https://namu.wiki/w/%EC%87%A0%EA%B3%A0%EA%B8%B0\n","beef = ['소고기', '쇠고기', '불고기', '떡갈비', '갈비찜', '소갈비', '육사시미', '육회', '장조림', '와규', '야키니쿠', '규동', '스테이크', '햄버그 스테이크',\n"," '함박스테이크', '함바그스테이크', '함박 스테이크', '햄버거', '로스트 디너', '비프가스밀라네사', '웰링턴', '슈하스쿠', '아사도', '우육면',\n"," '육개장', '육포', '평양냉면', '비프 스트로가노프', '설렁탕', '소고기국', '소머리국밥', '곰탕', '너비아니', '보르챠', '소꼬리']\n","# 돼지고기\n","# https://namu.wiki/w/%EB%8F%BC%EC%A7%80%EA%B3%A0%EA%B8%B0\n","pig = ['돼지', '돼지머리', '머릿고기', '뒷고기', '관자살', '콧등살', '삼각살', '설중살', '설하살', '안중살', '뽈항정살',\n"," '볼살', '두항정', '돼지코', '항정살', '목살', '가브리살', '갈비', '앞다리살', '갈매기살', '등심', '안심',\n"," '삼겹살', '오겹살', '뒷다리살', '돈족', '내장', '오소리감투', '허파', '염통', '콩팥', '새끼보', '돈낭',\n"," '돈족', '돼지꼬리', '사태', '막창', '감자탕', '돈가스', '돼지갈비', '돼지국밥', '돼지불고기', '두루치기', '순대',\n"," '순댓', '족발', '보쌈', '수육', '편육', '제육', '탕수육', '삼겹', '맥적', '차슈', '향우구육', '꿔바로우', '훙사오러우',\n"," '회과육', '동파육', '라후테', '오향장육', '슈바인스학세', '소시지', '소세지', '포크 커틀릿', '함바그 스테이크', '함바그스테이크',\n"," '함박스테이크', '살스테이크','살 스테이크', '함박 스테이크', '베이컨', '햄', '스팸', '폭립', '폭찹', '돈지루', '부타동', '바쿠테', '팟 카파오 무 쌉', '비엔나', '소떡', '육']\n","# 닭고기\n","# https://namu.wiki/w/%EB%8B%AD%EA%B3%A0%EA%B8%B0\n","chicken = ['닭', '깐풍기', '꼬꼬면', '궁보계정', '간장닭', '기스면', '계', '도빙무시', '라조기', '백숙', '영계백숙',\n"," '불닭', '삼계탕', '삼계선', '오니시메', '옻닭', '연팔기', '유린기', '육회', '좌종당계', '찜닭', '초계밀면',\n"," '치킨', '도리텐', '지파이', '치짜', '취계', '카라아게', '가라아', '파닭', '양파닭', '케밥', '코코뱅', '탕수기',\n"," '포계', '프랑구 아사두']\n","# 양고기\n","# https://namu.wiki/w/%EC%96%91%EA%B3%A0%EA%B8%B0\n","sheep = ['양고기','훠궈', '양꼬치', '케밥', '샤슬릭', '징기스칸', '셰퍼드 파이', '허르헉', '양갈비']\n","# 오리고기\n","# https://namu.wiki/w/%EC%98%A4%EB%A6%AC%EA%B3%A0%EA%B8%B0\n","dug = ['오리']\n","\n","web_keywords = beef + pig + chicken + sheep + dug\n","keywords = ['돈까스', '히레카츠', '히레까쓰', '히레가스', '포크', '부대찌개', '뒷다리', '앞다리', '돈', '순살',\n","                '소머리', '등뼈', '곱창', '도가니', '뼈해장국', '뼈다귀해장국', '목심', '채끝', '우둔', '양지', '설도', '만두', '만둣',\n","                '잡채', '류산슬', '유산슬', '고기', '고깃']\n","keywords += web_keywords\n","\n","not_in_keywords = {'오리':['아오리', '오리엔탈'], '계':['계란', '계발', '계피'], '장조림':['계란', '메추리알'], '치킨':['치킨무'], '돈':['돈나물'], '만두':['당면계란'], '만둣':['당면계란']}\n","meat_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKnOAxhvWARS"},"source":["# 돼지고기\n","keywords = ['돼지', '돼지머리', '머릿고기', '뒷고기', '관자살', '콧등살', '삼각살', '설중살', '설하살', '안중살', '뽈항정살',\n"," '볼살', '두항정', '돼지코', '항정살', '목살', '가브리살', '앞다리살', '갈매기살', '등심', '안심',\n"," '삼겹살', '오겹살', '앞다리살', '뒷다리살', '돈족', '내장', '오소리감투', '허파', '염통', '콩팥', '새끼보', '돈낭',\n"," '돈족', '돼지꼬리', '사태', '막창', '감자탕', '돈가스', '돼지갈비', '돼지국밥', '돼지불고기', '두루치기', '순대',\n"," '순댓', '족발', '보쌈', '수육', '편육', '제육', '탕수육', '삼겹', '맥적', '차슈', '향우구육', '꿔바로우', '훙사오러우',\n"," '회과육', '동파육', '라후테', '오향장육', '슈바인스학세', '소시지', '소세지', '포크 커틀릿',\n"," '목살스테이크','목살 스테이크', '베이컨', '햄', '스팸', '폭립', '폭찹', '돈지루', '부타동', '바쿠테', '팟 카파오 무 쌉', '비엔나', '소떡',\n"," '돈까스', '히레카츠', '히레까쓰', '히레가스', '포크', '돈', '등뼈', '뼈해장국', '뼈다귀해장국']\n","not_in_keywords = {'돈':['돈나물'], '만두':['당면계란'], '만둣':['당면계란']}\n","pig_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v3XDGiPNWAUA"},"source":["# 소고기\n","keywords = ['소고기', '쇠고기', '소불고기', '소갈비', '육사시미', '육회', '와규', '야키니쿠', '규동', '소곱창',\n","            '로스트 디너', '비프가스밀라네사', '웰링턴', '슈하스쿠', '아사도', '우육면',\n","            '육개장', '육포', '평양냉면', '비프 스트로가노프', '설렁탕', '소고기국', '소머리국밥', '곰탕', '너비아니', '보르챠', '소꼬리', '소머리', '설도', '목심', '채끝', '우둔', '양지', '도가니']\n","beef_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2AfAh-RjWAW0"},"source":["# 닭고기\n","keywords = ['닭', '깐풍기', '꼬꼬면', '궁보계정', '간장닭', '기스면', '계', '도빙무시', '라조기', '백숙', '영계백숙',\n","          '불닭', '삼계탕', '삼계선', '오니시메', '옻닭', '연팔기', '유린기', '육회', '좌종당계', '찜닭', '초계밀면',\n","          '치킨', '도리텐', '지파이', '치짜', '취계', '카라아게', '가라아', '파닭', '양파닭', '케밥', '코코뱅', '탕수기',\n","          '포계', '프랑구 아사두']\n","not_in_keywords = {'계':['계란', '계발', '계피'], '치킨':['치킨무']}\n","\n","chicken_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_TAp8l6WAZc"},"source":["# 양고기 - 데이터 없어서 제외\n","keywords = ['양고기','훠궈', '양꼬치', '케밥', '샤슬릭', '징기스칸', '셰퍼드 파이', '허르헉', '양갈비']\n","sheep_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])\n","sheep_menus"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uwgAsChgWAcU"},"source":["# 오리고기\n","keywords = ['오리']\n","not_in_keywords = {'오리':['아오리', '오리엔탈']}\n","duck_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxHWyYJiXB3m"},"source":["#난류 (계란)\n","keywords = ['계란', '난', '란', '메추리알', '날치알', '동태알']\n","not_in_keywords = {\"란\":['토란'], '난':['커리', '카레']}\n","egg_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CyTSZwFUXB58"},"source":["# 죽류\n","keywords = ['죽', '누룽지']\n","juk_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQ1ifPoVXB8W"},"source":["# 덮밥 및 국밥류\n","keywords = ['덮밥', '국밥']\n","gukbob_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"StMSgU-wXB-s"},"source":["# 비빔밥 및 볶음밥류\n","keywords = ['비빔밥', '볶음밥']\n","bb_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8iARJ76XCA8"},"source":["# 국탕류\n","keywords = ['국', '탕', '찌개', '국물']\n","soup_menus = extractMenu2(tot_menu_arr, keywords=keywords)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FlIw-tp5XCDT"},"source":["# 구이류\n","keywords = ['구이']\n","gui_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ojhRqgQ6XCFs"},"source":["# 전류\n","keywords = ['전', '부침개', '빈대떡']\n","jeon_menus = extractMenu2(tot_menu_arr, keywords=keywords)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5z-ew31XXCIJ"},"source":["# http://yaksik.net/detail.php?number=24904\n","# 튀김류\n","keywords = ['튀김', '까스', '카츠', '가츠', '까츠', '탕수', '덴뿌라', '덴푸라', '크로켓', '고로케', '맛탕', '치킨', '통닭', '부각', '강정', '김말이', '깐풍']\n","fry_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IOTl9sDnXCKz"},"source":["#### 메뉴 추가 특성 - Part1"]},{"cell_type":"code","metadata":{"id":"iJZkXn4CXCNL"},"source":["# 곡물\n","keywords = ['현미', '밥', '쌀', '보리', '죽', '참깨', '들깨', '수수', '잡곡', '귀리', '퀴노아', '아마란스', '옥수수', '기장', '메밀', '모밀']\n","grain_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FN-p1XyWXCPs"},"source":["# 콩류\n","keywords = ['콩', '녹두', '팥', '완두']\n","not_in_keywords = {'콩':['콩나물']}\n","bean_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vUKF70qXCSH"},"source":["# 묵\n","keywords = ['묵']\n","not_in_keywords = {'묵':['어묵', '묵은지']}\n","kor_jelly_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2US2k7ARXRKy"},"source":["# 생선 및 조개류\n","# https://ko.wikipedia.org/wiki/%EC%83%9D%EC%84%A0\n","# https://namu.wiki/w/%EC%83%9D%EC%84%A0\n","# https://namu.wiki/w/%EC%A1%B0%EA%B0%9C\n","keywords = ['생선', '조개', '메기', '송어', '오징어', '굴', '멸치', '숭어', '성게', '고등어', '명태',\n","            '쏨뱅이', '연어', '틸라피아', '우럭', '이리치', '가재', '참바리', '상어', '돔',\n","            '삼치', '방어', '참치', '새우', '문어', '홍어', '농어', '붉평치', '청상아리', '황새치',\n","            '다랑어', '비막치어', '장어', '녹새치', '숭어', '굴비', '조기', '갈치', '꽁치',\n","            '전어', '명태', '노가리', '황태', '은어', '가물치', '쏘가리', '붕어', '잉어', '모래마주', '가자미',\n","            '간재미', '가오리', '박대', '양미리', '과메기', '청어', '생태',\n","            '개복치', '광어', '넙치', '기름치', '까나리', '날치','놀래미'\n","            ,'능성어','달고기','대구','도다리','도루묵','도미','독가시치'\n","            ,'만새기','망상어','문절망둑','물메기','미꾸라지','민어','방어'\n","            ,'추어탕','배스','밴댕이','뱅어','벵에돔','병어','보리멸'\n","            ,'복어','볼락','부세','부시리','붕장어','블루길'\n","            ,'빙어','산천어','서대','시샤모','쏘가리','쏠배감펭','쏨뱅이'\n","            ,'아귀','아구','임연수','전갱이','전복치','점성어','정어리'\n","            ,'준치','쥐치','청새치','청어','향어','홍어','황새치','매운탕'\n","            ,'루테피스크','게맛살','물회','회덮밥','부야베스','북엇국','세꼬시','수르스트뢰밍','식해','어묵','오뎅'\n","            ,'쥐포','추어탕','피시 앤드 칩스','피쉬 앤드 칩스','피시앤드칩스','피쉬앤드칩스','피시앤칩스','피쉬앤칩스','해물'\n","            ,'가리비', '개오지', '꼬막','대칭이','바지락','백합','홍합','소라', '골뱅이', '고둥','재첩'\n","            ,'전복','플라티케라무스', '봉골레', '클램차우더']\n","not_in_keywords = {'굴':['굴소스'], '새우':['새우젓']}\n","fish_shell_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yB7hgjC-XRV6"},"source":["# 채소류\n","# https://namu.wiki/w/%EC%B1%84%EC%86%8C?from=%EC%95%BC%EC%B1%84\n","keywords = ['가지', '갓', '감자', '고구마', '고사리', '고추', '페페론치노', '냉이', '근대', '깻잎', '차조기'\n","            , '당근', '더덕', '도라지', '동아', '딸기', '마', '마늘', '멜론', '무', '무청'\n","            , '바나나', '배추', '버섯', '부추', '브로콜리', '상추', '생강', '쇠비름', '나물'\n","            , '쑥', '시금치', '수박', '시호', '아스파라거스', '야콘', '양파', '여주', '연근', '열무', '오이'\n","            , '우엉', '인삼', '죽순', '청경채', '참외', '칡', '풋콩', '토란', '토마토', '쪽파', '대파', '파인애플'\n","            , '파프리카', '피망', '케일', '고수', '로즈마리', '루타바가', '바질', '박하', '산마늘', '셀러리'\n","            , '아티초크', '타임', '파슬리', '호박', '피클', '파채', '파김치', '채소', '야채']\n","not_in_keywords = {'무':['무침'], '마':'마카로니', '고추':['고추장']}\n","vegetable_menus =  extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJMsnF72XRYC"},"source":["# 해조류\n","# https://namu.wiki/w/%EC%A1%B0%EB%A5%98(%EC%88%98%EC%A4%91%EC%83%9D%EB%AC%BC)?from=%ED%95%B4%EC%A1%B0%EB%A5%98\n","keywords = ['김', '우뭇가사리', '한천', '매생이', '파래', '바다포도', '해캄', '클로렐라', '청각', '마리모모스볼', '다시마', '미역', '감태', '톳']\n","not_in_keywords = {'김':['김치', '튀김', '김칫']}\n","sea_alg_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OYqKGcDIXRaZ"},"source":["# 발효된 콩 상품 -> 장류\n","# https://namu.wiki/w/%EC%9E%A5%EB%A5%98\n","keywords = ['된장', '간장', '쯔유', '노추', '미소', '고추장', '청국장', '담북장', '팥장', '두부장', '비지장', '어육장', '춘장', '마장', '낫토', '두반장', '해선장', '굴소스', '게장',\n"," '장조림', '양념장', '장국', '쌈장', '초장', '*장']\n","jang_menus  = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iDRW_hfWXRcq"},"source":["# 김치\n","# https://namu.wiki/w/%EA%B9%80%EC%B9%98\n","keywords = ['김치', '깍두기', '석박지', '동치미', '겉절이', '묵은지', '소박이', '섞박지', '생채', '게국지', '김칫']\n","kimchi_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mOWHrUdWXRe7"},"source":["# 만두\n","# https://namu.wiki/w/%EB%A7%8C%EB%91%90\n","keywords = ['만두', '춘권', '만쥬', '사모사', '만둣']\n","mandu_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CeOWgVlBXRhA"},"source":["# 곡물 가루(밀가루, 쌀가루 등 전분)\n","# https://namu.wiki/w/%EB%B0%80%EA%B0%80%EB%A3%A8\n","# 미숫가루\n","keywords = [\"면\", \"수제비\", \"전\", \"부침개\", \"빵\", \"춘권\", \"튀김\", \"과자\", \"국수\", \"메밀\", \"모밀\", \"피자\", \"전병\", \"떡\", \"어묵\", \"오뎅\", \"소시지\", \"소세지\", \"햄\", \"김밥\", \n","            \"부대찌개\", \"스콘\", \"만두\", \"파이\", \"빈대떡\", \"케이크\", \"케익\", \"쿠키\", \"핫도그\", \"파스타\", \"치킨\", \"라자냐\", \"팟타이\", \"나쵸\", \"팝콘\", '스파게티', '짬뽕']\n","not_in_keywords = {'치킨':['치킨무'], '전':['전주식'], '짬뽕':['고기', '찌개', '국']}\n","powder_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iPzKj_zDXRja"},"source":["# 과일\n","# https://namu.wiki/w/%EA%B3%BC%EC%9D%BC\n","# https://namu.wiki/w/%EC%88%98%EC%9E%85%20%EA%B3%BC%EC%9D%BC\n","keywords = ['구기자','매실','무화과','버찌','체리','복분자','복숭아','블랙베리','블루베리','딸기','살구','앵두','자두','포도'\n","            ,'감','다래','대추','머루','모과','무화과','배','사과','석류','으름','귤','유자','레드향','천혜향','한라봉'\n","            ,'과라나','구아바','구즈베리','토마토','나랑히야','노니','노팔','니파팜','두꾸','두리안','라임','람부탄'\n","            ,'레몬','애플','루비솔트부쉬','리치','여지','마랑','마룰라','마르멜로','마프랑','망고','블랙베리','아보카도'\n","            ,'아로니아','아사이베리','아사이 베리','양초열매','오렌지','올리브','용안','롱간','자몽','바나나','딸기','수박'\n","            ,'참외','멜론','메론','여주','파인애플','토마토','코코넛','크랜베리','타마린드','파파야','패션프루트','패션후르츠']\n","not_in_keywords = {'살구':['구이', '목살', '삼겹살', '가브리살', '갈비살', '항정살'], '감':['감자'], '배':['배추', '알배기', '소배기']}\n","comm_not_in = ['주스', '쥬스', '음료', 'D', '순']\n","fruit_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=comm_not_in)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EBtM9sFKXRl4"},"source":["#### 메뉴 추가 특성 - Part2"]},{"cell_type":"code","metadata":{"id":"AIdXBrVoXaFU"},"source":["# 쌀\n","# https://namu.wiki/w/%EA%B3%A1%EB%AC%BC\n","\n","keywords = ['쌀', '잡곡', '오곡', '현미', '흑미', '귀리', '차조', '렌틸콩', '강낭콩', '병아리콩', '완두콩', '기장', '보리', '수수', '호밀'] \n","not_in_keywords = {'쌀':['쌀국수', '찹쌀'], '기장':['장조림'], '수수':['옥수수', '부꾸미']} # 찹쌀은 밥 메뉴명에 쓰이지 않아 삭제\n","comm_not_in = ['스프']\n","rice_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qiMv_OG_XaHp"},"source":["# 김밥 및 초밥\n","\n","keywords = ['김밥', '초밥'] \n","not_in_keywords = {'김밥':['볶음밥']}\n","comm_not_in = []\n","gimbab_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VOMlkPacXaKf"},"source":["# 소금, 식초 등에 절인 해산물\n","# 해산물이 들어있지 않은 절임류도 포함시킴\n","\n","keywords = ['절임', '젓'] \n","not_in_keywords = {}\n","comm_not_in = []\n","saused_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1O__IsbXaMz"},"source":["# 면류\n","# https://femiwiki.com/w/%EB%B6%84%EB%A5%98:%EC%A2%85%EB%A5%98/%EB%A9%B4%EC%9A%94%EB%A6%AC\n","keywords = ['국수', '면', '파스타', '스파게티', '짬뽕', '라면'] \n","not_in_keywords = {'짬뽕':['고기', '찌개', '국']}\n","comm_not_in = []\n","noodle_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcy3XJygXaUh"},"source":["# 스튜 - 조림과 찌개의 중간단계\n","# https://namu.wiki/w/%EC%8A%A4%ED%8A%9C\n","keywords = ['스튜', '조림'] \n","not_in_keywords = {}\n","comm_not_in = []\n","stew_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YPu1f9HXXaVe"},"source":["# 한국 전통 샐러드\n","keywords = ['나물', '무침'] \n","not_in_keywords = {'나물':['콩나물', '밥']}\n","comm_not_in = []\n","namul_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nrpEnKRWXaWg"},"source":["# 피클\n","keywords = ['피클'] \n","not_in_keywords = {}\n","comm_not_in = []\n","pickle_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoSQ38enXaXX"},"source":["# 뚝배기 - 없음 -> 제외\n","keywords = ['뚝배기', '돌솥'] \n","not_in_keywords = {}\n","comm_not_in = []\n","dduk_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)\n","\n","dduk_menus"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"owC8qMfmXaYa"},"source":["# 샐러드\n","keywords = ['샐러드'] \n","not_in_keywords = {}\n","comm_not_in = []\n","salad_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hhOR7p_BXaZN"},"source":["# 우유\n","# 우유가 들어간 식재료(크림, 요거트 등)종류로 변경\n","keywords = ['까르보나라', '크림', '요거트'] \n","not_in_keywords = {}\n","comm_not_in = ['샐러드', 'D', '드레싱', '소스'] # 샐러드 드레싱, 디핑소스 제외\n","milk_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubxLJWyCXaaR"},"source":["# 빵, 쿠키\n","# https://ko.wikipedia.org/wiki/%EB%B9%B5_%EB%AA%A9%EB%A1%9D\n","keywords = ['와플', '케이크', '케잌', '바게트', '도넛', '도너츠', '핫도그', '도라야키', '베이글', '번', '비스킷', '스콘', '토스트', '브레드', '포카차', '피자', '호두과자', '쿠키'] \n","not_in_keywords = {}\n","comm_not_in = []\n","bread_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2E-6jg0hXabR"},"source":["# 음료\n","# https://ko.wikipedia.org/wiki/%EB%B9%B5_%EB%AA%A9%EB%A1%9D\n","keywords = ['주스', '쥬스', '수정과', '식혜', '식초', '코코아', '칵테일', '스무디', '우유', '셰이크', '야쿠르트', '요구르트', '커피', '차', '탄산수', '음료'] \n","not_in_keywords = {'차':['차돌']}\n","comm_not_in = []\n","drink_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9iZRFoUjXacM"},"source":["def get_food_one_hot(x, menu_array):\n","  menu_list = x.strip().split()\n","  for i, menu_nm in enumerate(menu_list):\n","    menu_nm = re.sub(pattern, '', menu_nm)\n","    if menu_nm.strip() in ['', '*']:\n","      continue\n","    if menu_nm[0] == '(' or menu_nm[-1] == ')':\n","      continue\n","    try:\n","      if menu_array.index(menu_nm) > -1:\n","        return 1\n","    except Exception:\n","      pass\n","  return 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oHf-0jV0XadL"},"source":["# 데이터 병합\n","menu_col_nm = ['육류', '난류', '죽류', '덮밥_국밥류', '비빔밥_볶음밥류', '국탕류', '구이류', '전류', '튀김류', '곡물', '콩류',\n","               '묵', '생선_조개류', '채소류', '해조류', '장류', '김치', '만두', '곡물가루', '과일', '쌀', '김밥_초밥', '절임류',\n","               '면류', '스튜', '나물_무침류', '피클', '샐러드', '우유', '빵류', '음료', '돼지고기', '소고기', '닭고기', '오리고기']\n","menu_data_arr = [meat_menus, egg_menus, juk_menus, gukbob_menus, bb_menus, soup_menus, gui_menus, jeon_menus, fry_menus, grain_menus, bean_menus,\n","                 kor_jelly_menus, fish_shell_menus, vegetable_menus, sea_alg_menus, jang_menus, kimchi_menus, mandu_menus, powder_menus, fruit_menus, rice_menus, gimbab_menus, saused_menus,\n","                 noodle_menus, stew_menus, namul_menus, pickle_menus, salad_menus, milk_menus, bread_menus, drink_menus, pig_menus, beef_menus, chicken_menus, duck_menus]\n","\n","for col_type in ['중식메뉴', '석식메뉴']:\n","  for i, menu_arr in enumerate(menu_data_arr):\n","    train[col_type + '_' + menu_col_nm[i]] = train[col_type].apply(lambda x: get_food_one_hot(x, menu_arr))\n","    test[col_type + '_' + menu_col_nm[i]] = train[col_type].apply(lambda x: get_food_one_hot(x, menu_arr))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6aJ3oa43XaeD"},"source":["df = pd.concat([train, test], axis=0).reset_index(drop=True)\n","df = df.fillna(0)\n","df.columns = ['일자', '요일', '정원', '휴가자', '출장자', '야근자', '재택근무자', '조식', '중식', '석식',\\\n","              '중식계', '석식계', '중식메뉴_육류',\n","       '중식메뉴_난류', '중식메뉴_죽류', '중식메뉴_덮밥_국밥류', '중식메뉴_비빔밥_볶음밥류', '중식메뉴_국탕류',\n","       '중식메뉴_구이류', '중식메뉴_전류', '중식메뉴_튀김류', '중식메뉴_곡물', '중식메뉴_콩류', '중식메뉴_묵',\n","       '중식메뉴_생선_조개류', '중식메뉴_채소류', '중식메뉴_해조류', '중식메뉴_장류', '중식메뉴_김치', '중식메뉴_만두',\n","       '중식메뉴_곡물가루', '중식메뉴_과일', '중식메뉴_쌀', '중식메뉴_김밥_초밥', '중식메뉴_절임류', '중식메뉴_면류',\n","       '중식메뉴_스튜', '중식메뉴_나물_무침류', '중식메뉴_피클', '중식메뉴_샐러드', '중식메뉴_우유', '중식메뉴_빵류',\n","       '중식메뉴_음료', '중식메뉴_돼지고기', '중식메뉴_소고기', '중식메뉴_닭고기', '중식메뉴_오리고기', '석식메뉴_육류',\n","       '석식메뉴_난류', '석식메뉴_죽류', '석식메뉴_덮밥_국밥류', '석식메뉴_비빔밥_볶음밥류', '석식메뉴_국탕류',\n","       '석식메뉴_구이류', '석식메뉴_전류', '석식메뉴_튀김류', '석식메뉴_곡물', '석식메뉴_콩류', '석식메뉴_묵',\n","       '석식메뉴_생선_조개류', '석식메뉴_채소류', '석식메뉴_해조류', '석식메뉴_장류', '석식메뉴_김치', '석식메뉴_만두',\n","       '석식메뉴_곡물가루', '석식메뉴_과일', '석식메뉴_쌀', '석식메뉴_김밥_초밥', '석식메뉴_절임류', '석식메뉴_면류',\n","       '석식메뉴_스튜', '석식메뉴_나물_무침류', '석식메뉴_피클', '석식메뉴_샐러드', '석식메뉴_우유', '석식메뉴_빵류',\n","       '석식메뉴_음료', '석식메뉴_돼지고기', '석식메뉴_소고기', '석식메뉴_닭고기', '석식메뉴_오리고기']\n","df.drop(columns=['조식', '중식', '석식'], inplace=True)\n","# 중간 변수 색출\n","df = df.drop(columns=['중식메뉴_죽류', '중식메뉴_곡물', '중식메뉴_김치', '중식메뉴_쌀', '중식메뉴_나물_무침류', '중식메뉴_피클'\n","                        , '석식메뉴_죽류', '석식메뉴_곡물', '석식메뉴_김치', '석식메뉴_쌀', '석식메뉴_나물_무침류', '석식메뉴_피클',\\\n","                      '중식메뉴_음료', '석식메뉴_음료'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-pzgB1IlYEdj"},"source":["### 날씨 데이터 추가"]},{"cell_type":"code","metadata":{"id":"iuRdurT0YVTq"},"source":["weather_path = '/content/drive/MyDrive/구내식당/water/날씨'\n","\n","w_attrs = ['3시간기온', '강수형태', '강수확률', '습도', '6시간강수량']\n","w_years = os.listdir(weather_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZpu8cLLYX7F"},"source":["def get_wdata(data_path) :\n","    datetime_list = []\n","    value_list_12 = []\n","    value_list_18 = []\n","    curr_mon = ''\n","\n","    with open(data_path, 'r') as f :\n","        lines = f.readlines()\n","        for i, line in enumerate(lines) :\n","            if line.strip() == '' :\n","                break\n","            row_data = line.strip().split(',')\n","            row_data = [elem.strip() for elem in row_data]\n","            if i == 0 :\n","                curr_mon = row_data[-1].split()[-1][:-2]\n","                continue\n","            if len(row_data) == 1 :\n","                curr_mon =row_data[-1].split()[-1][:-2]\n","                continue\n","            r_day, r_hour, r_fore, r_temp = row_data\n","            if '6시간' not in data_path :\n","                if r_hour == '1400' and r_fore in ['+13', '+19']:\n","                    if r_fore in '+13' :\n","                        datetime_list.append(curr_mon[:4]+'-'+curr_mon[4:]+'-'+str('%02d'%int(r_day)))\n","                    if r_fore == '+13' :\n","                        value_list_12.append(float(r_temp))\n","                    else :\n","                        value_list_18.append(float(r_temp))\n","            else :\n","                if r_hour == '1400' and r_fore in ['+13', '+19']:\n","                    if r_fore in '+13' :\n","                        datetime_list.append(curr_mon[:4]+'-'+curr_mon[4:]+'-'+str('%02d'%int(r_day)))\n","                    if r_fore == '+13' :\n","                        value_list_12.append(float(r_temp))\n","                    else :\n","                        value_list_18.append(float(r_temp))\n","\n","        if data_path == '/content/drive/MyDrive/구내식당/water/정훈/날씨/2017/충무공동_강수형태_201701_201712.csv' :\n","            nan_val = [0]*22\n","            nan_val[-7] = 1\n","            nan_val[-6] = 1\n","            nan_val[-2] = 1 \n","            value_list_12.extend(nan_val)\n","            value_list_18.extend(nan_val)\n","    return datetime_list, value_list_12, value_list_18"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-SX5tXRaYX-J"},"source":["# ['3시간기온', '강수형태', '강수확률', '습도', '하늘상태']\n","w_data_rain_12 = []\n","w_data_rain_18 = []\n","w_data_rtype_12 = []\n","w_data_rtype_18 = []\n","w_data_hum_12 = []\n","w_data_hum_18 = []\n","w_data_temp_12 = []\n","w_data_temp_18 = []\n","w_data_rain_total_12 = []\n","w_data_rain_total_18 = []\n","w_datetime = []\n","\n","for year in w_years :\n","    w_subdir = os.path.join(weather_path, year)\n","    file_names = os.listdir(w_subdir)\n","    file_name = \"\"\n","    if year != '2021' :\n","        file_name = f'{year}01_{year}12.csv'\n","    else :\n","        file_name = f'{year}01_{year}06.csv'\n","    file_path_rain = os.path.join(w_subdir, '충무공동_강수확률_'+file_name)\n","    file_path_temp = os.path.join(w_subdir, '충무공동_3시간기온_'+file_name)\n","    file_path_hum = os.path.join(w_subdir, '충무공동_습도_'+file_name)\n","    file_path_rtype = os.path.join(w_subdir, '충무공동_강수형태_'+file_name)\n","    file_path_rain_total = os.path.join(w_subdir, '충무공동_6시간강수량_'+file_name)\n","\n","    datetime_list_temp, value_list_temp_12, value_list_temp_18 = get_wdata(file_path_temp) # 3시간기온 데이터\n","    datetime_list_rain, value_list_rain_12, value_list_rain_18 = get_wdata(file_path_rain) # 강수확률 데이터\n","    datetime_list_hum, value_list_hum_12, value_list_hum_18 = get_wdata(file_path_hum) # 습도 데이터\n","    datetime_list_rtype, value_list_rtype_12, value_list_rtype_18 = get_wdata(file_path_rtype) # 강수형태 데이터\n","    datetime_list_rain_total, value_list_rain_total_12, value_list_rain_total_18 = get_wdata(file_path_rain_total) # 강수량 데이터\n","\n","    w_datetime   += datetime_list_temp\n","    w_data_rain_12  += value_list_rain_12\n","    w_data_temp_12  += value_list_temp_12\n","    w_data_hum_12   += value_list_hum_12\n","    w_data_rtype_12 += value_list_rtype_12\n","    w_data_rain_18  += value_list_rain_18\n","    w_data_temp_18  += value_list_temp_18\n","    w_data_hum_18   += value_list_hum_18\n","    w_data_rtype_18 += value_list_rtype_18\n","    w_data_rain_total_12 += value_list_rain_total_12\n","    w_data_rain_total_18 += value_list_rain_total_18"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Pm8Bx0BYYBS"},"source":["w_df = pd.DataFrame({'일자':pd.Series(w_datetime, dtype='datetime64[ns]'),\n","                   'rain_prob_lunch':pd.Series(w_data_rain_12, dtype='float'),\n","                   'temp_lunch':pd.Series(w_data_temp_12, dtype='float'),\n","                   'hum_lunch':pd.Series(w_data_hum_12, dtype='float'),\n","                   'rain_total_lunch':pd.Series(w_data_rain_total_12, dtype='float'),\n","                   'rain_type_lunch':pd.Series(w_data_rtype_12, dtype='float'),\n","                   'rain_prob_dinner':pd.Series(w_data_rain_18, dtype='float'),\n","                   'temp_dinner':pd.Series(w_data_temp_18, dtype='float'),\n","                   'hum_dinner':pd.Series(w_data_hum_18, dtype='float'),\n","                   'rain_total_dinner':pd.Series(w_data_rain_total_18, dtype='float'),\n","                   'rain_type_dinner':pd.Series(w_data_rtype_18, dtype='float'),}).sort_values('일자').reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJMYKxpPYYDb"},"source":["# 불쾌지수 컬럼 추가\n","# https://dacon.io/competitions/official/235736/codeshare/2753?page=1&dtype=recent\n","w_df['discomfort_lunch'] = 1.8*w_df['temp_lunch'] - 0.55*(1-w_df['hum_lunch']/100)*(1.8*w_df['temp_lunch']-26) + 32\n","w_df['discomfort_dinner'] = 1.8*w_df['temp_dinner'] - 0.55*(1-w_df['hum_dinner']/100)*(1.8*w_df['temp_dinner']-26) + 32\n","\n","# 불쾌지수 명목변수화 \n","w_df['discomfort_lunch'] = w_df['discomfort_lunch'].apply(lambda x : 0 if x<68 else (1 if 68<=x<75 else (2 if 75<=x<80 else 3)))\n","w_df['discomfort_dinner'] = w_df['discomfort_dinner'].apply(lambda x : 0 if x<68 else (1 if 68<=x<75 else (2 if 75<=x<80 else 3)))\n","\n","# 진주에는 눈이 거의 내리지 않음 -> 비로 고쳐주겠음\n","w_df['rain_type_lunch'] = w_df['rain_type_lunch'].apply(lambda x : 0 if x==0 else 1)\n","w_df['rain_type_dinner'] = w_df['rain_type_dinner'].apply(lambda x : 0 if x==0 else 1)\n","\n","w_df['rain_prob_lunch'] = w_df['rain_prob_lunch'].apply(lambda x : np.round(x/100, 1))\n","w_df['rain_prob_dinner'] = w_df['rain_prob_dinner'].apply(lambda x : np.round(x/100, 1))\n","w_df.drop(columns=['temp_lunch', 'temp_dinner', 'hum_lunch', 'hum_dinner'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n6c6cMFbYYGu"},"source":["w_df['일자'] = w_df['일자'].shift(-1)\n","df['일자'] = df['일자'].astype('datetime64')\n","df = pd.merge(df, w_df, on='일자', how='left')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"unTv9uriXahy"},"source":["### 파생 변수 - Feature_pipeline"]},{"cell_type":"code","metadata":{"id":"GSxtHMvyXair"},"source":["def feature_pipeline(df) :\n","    df['식사가능인원'] = df['정원']-(df['휴가자']+df['출장자']+df['재택근무자'])+df['야근자']\n","    df['년'] = df['일자'].dt.year\n","    df['월'] = df['일자'].dt.month\n","    df['일'] = df['일자'].dt.day\n","    df['년월'] = df['년'].astype('str')+'_'+df['월'].astype('str')\n","\n","    first_dayofmonth = []\n","    last_dayofmonth = []\n","    for i in df['년월'].unique() :\n","        first_dayofmonth.append(df[df['년월']==i].iloc[0].name)\n","        last_dayofmonth.append(df[df['년월']==i].iloc[-1].name)\n","    df['첫_출근일'] = df.apply(lambda x : 1 if x.name in first_dayofmonth else 0, axis=1)\n","    df['마지막_출근일'] = df.apply(lambda x : 1 if x.name in last_dayofmonth else 0, axis=1)\n","\n","    # 월_주차 컬럼 추가\n","    df['주차'] = df['일자'].apply(lambda x: pendulum.parse(str(x)).week_of_month)\n","    repair_2017 = df[(df['년']==2017)&(df['주차']<0)]['일자'].dt.week\n","    repair_2021 = df[(df['년']==2021)&(df['주차']<0)]['일자'].dt.week\n","    df['주차'][list(repair_2017.index)] = repair_2017.values\n","    df['주차'][list(repair_2021.index)] = repair_2021.values\n","    df['주차'][[709, 954, 955]] = np.array([6, 5, 5])\n","\n","    month_to_season = {1: 3,2: 3,3:0,4:0,5:0,6:1,7:1,8:1,9:2,10:2,11:2,12: 3}\n","    df['계절'] = df['월'].apply(lambda x : month_to_season[x])\n","    df['요일'] = df['일자'].dt.weekday\n","    df['야근_가능'] = df['요일'].apply(lambda x : 1 if (x==2) or (x==4) else 0)\n","    df['is_corona'] = df['일자'].apply(lambda x : 0 if x < pd.to_datetime('2020-01-06') else 1)\n","    df['연기준몇주째']= df['일자'].dt.weekofyear\n","    df['월마지막일여부'] =df['일자'].dt.is_month_end\n","    df['월일수']= df['일자'].dt.days_in_month\n","\n","    # 공휴일 데이터 추가\n","    holiday['date'] = pd.to_datetime(holiday['date'])\n","    df['before_holiday'] = df['일자'].apply(lambda x : 1 if (x+dt.timedelta(1) in holiday['date'].tolist()) else 0)\n","    df['after_holiday'] = df['일자'].apply(lambda x : 1 if (x-dt.timedelta(1) in holiday['date'].tolist()) else 0)\n","    \n","    # 탄력근무제 적용 여부\n","    test_date=\"20180701\"\n","    convert_date = datetime.datetime.strptime(test_date, \"%Y%m%d\").date()\n","    df['탄력근무_여부'] = df['일자'].apply(lambda x : 1 if x >= convert_date else 0)\n","\n","    # # 이벤트 데이터 고민 - 복날 / 연말\n","    bok = pd.to_datetime(['2016-08-16', '2016-07-27', '2016-07-18', '2017-08-11', '2017-07-21','2017-07-12', '2018-08-16', '2018-07-27', '2018-07-17', '2019-08-12', '2019-07-22', '2019-07-12', '2020-07-27', '2020-07-16'])\n","    df['복날'] = df['일자'].apply(lambda x : 1 if x in bok else 0)\n","\n","    # end_year = df[(df['월']==12)&(df['일']>=21)].index\n","    # df['연말'] = df.apply(lambda x : 1 if  x.name in end_year else 0, axis=1)\n","\n","    # 명절 전 영업일 여부\n","    event = pd.to_datetime(['2016-02-05', '2019-09-13', '2017-01-26','2017-09-29', '2018-02-14', '2018-09-21', '2019-02-01', '2019-09-11', '2020-01-23', '2020-09-30', '2021-02-10'])\n","    df['명절_이전_영업일'] = df['일자'].apply(lambda x : 1 if x in event else 0)\n","\n","    # 명절 전이나 둘 중에 하나만 써야함 / 특히 10월달이 이상함\n","    # df['긴_연휴'] = df['일자'].diff().dt.days.fillna(0).astype('int')\n","    # df['연휴_뒤'] = df['긴_연휴'].apply(lambda x: 1 if x>=4 else 0)\n","    # df['연휴_앞'] = df.apply(lambda x : 1 if x.name in df[df['연휴_뒤']==1].index-1 else 0, axis=1)\n","    # df.drop(columns=['긴_연휴'], inplace=True)\n","\n","    # 국정 감사 기간\n","    gukgam = pd.to_datetime(['2016-10-04', '2016-10-05', '2016-10-06', '2017-10-10', '2017-10-11', '2017-10-12', '2017-10-13', '2018-10-08', '2018-10-10', '2018-10-11',\\\n","                             '2019-10-02', '2019-10-04'])\n","    df['국정감사'] = df['일자'].apply(lambda x : 1 if x in gukgam else 0)\n","\n","    # 인원 변화\n","    # df['인원변화'] = df['정원'].diff()\n","    # df['인원변화'][0] = 0\n","\n","    df.drop(columns=['정원', '년월'], inplace=True)\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_YsxW2bXajn"},"source":["df = feature_pipeline(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pqzJvhdjZmms"},"source":["### 이상치 제거\n","* 수요일 야근자가 100명 이상, 정책 변경 후 금요일 100명 이상 제거\n","* 식사비율이 이상치에 해당하는 값 제거\n","    * 1.5*(제 3분위 수 - 제 1분위 수)"]},{"cell_type":"code","metadata":{"id":"KkqcvxZQXalg"},"source":["df['중식비율'] = df['중식계']/df['식사가능인원']\n","df['석식비율'] = df['석식계']/df['식사가능인원']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aWD_tVNoZj2J"},"source":["df = df[~df.index.isin(df[(df['요일']==2)&(df['야근자']>=100)].index.append(df[(df['요일']==4)&(df['일자']>='2019-01-01')&(df['야근자']>100)].index))]\n","\n","train = df.iloc[:-50]\n","train['월마지막일여부'] = train['월마지막일여부'].astype(int)\n","test = df.iloc[-50:]\n","\n","train_2 = train[train['석식계']!=0]\n","iqr_lunch = 1.5*(train['중식비율'].quantile(0.75) - train['중식비율'].quantile(0.25))\n","iqr_dinner = 1.5*(train_2['석식비율'].quantile(0.75) - train_2['석식비율'].quantile(0.25))\n","\n","train_1 = train[(train['중식비율']>=train['중식비율'].quantile(0.25)-iqr_lunch)|(train['중식비율']<=train['중식비율'].quantile(0.75)+iqr_lunch)]\n","train_2 = train_2[train_2['일자']!='2016-10-05']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5mHde7YoZ5TQ"},"source":["## Encoding"]},{"cell_type":"code","metadata":{"id":"RgeyqxO7Z9SL"},"source":["def get_one_hot(x, target_val):\n","  if x == target_val:\n","    return 1\n","  else:\n","    return 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jGmQZfKtZ9aJ"},"source":["from sklearn.preprocessing import LabelEncoder\n","onehot_col = ['년', '월', '요일', '계절']\n","# onehot_col = ['월', '요일', '계절']\n","# df_tmp = df.copy()\n","# df = pd.concat([df[list((set(df.columns)-set(onehot_col)))],\\\n","#                 pd.get_dummies(df[onehot_col])], axis=1)\n","\n","sub_types = [[2016, 2017, 2018, 2019, 2020, 2021], [1,2,3,4,5,6,7,8,9,10,11,12], [0,1,2,3,4], [0,1,2,3]]\n","# sub_types = [[1,2,3,4,5,6,7,8,9,10,11,12], [0,1,2,3,4], [0,1,2,3]]\n","\n","train_lun = train_1.copy()\n","train_din = train_2.copy()\n","# for i, col_type in enumerate(onehot_col):\n","#   for j, class_nm in enumerate(sub_types[i]):\n","#     df_tmp[col_type + '_' + str(class_nm)] = df_tmp[col_type].apply(lambda x: get_one_hot(x, class_nm))\n","\n","for i, col_type in enumerate(onehot_col):\n","  for j, class_nm in enumerate(sub_types[i]):\n","    train_lun[col_type + '_' + str(class_nm)] = train_lun[col_type].apply(lambda x: get_one_hot(x, class_nm))\n","for i, col_type in enumerate(onehot_col):\n","  for j, class_nm in enumerate(sub_types[i]):\n","    train_din[col_type + '_' + str(class_nm)] = train_din[col_type].apply(lambda x: get_one_hot(x, class_nm))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P5Vz960DZ9bQ"},"source":["train_1 = train_lun[[i for i in train_lun.columns if ('석식' not in i) and ('dinner' not in i) and ('탄력근무' not in i) and ('명절' not in i)]]\n","train_2 = train_din[[i for i in train_din.columns if ('중식' not in i) and ('lunch' not in i)]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Smi3fv7kZ9cc"},"source":["for i, col_type in enumerate(onehot_col):\n","  for j, class_nm in enumerate(sub_types[i]):\n","    test[col_type + '_' + str(class_nm)] = test[col_type].apply(lambda x: get_one_hot(x, class_nm))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-GEx5PEQZ9dj"},"source":["train_1 = train_1.drop(columns=['일자', '요일', '월', '월마지막일여부', '계절', '월일수','복날', '중식비율', '년', '국정감사'])\n","train_2 = train_2.drop(columns=['일자', '요일', '월', '월마지막일여부', '월일수','계절', '복날', 'after_holiday', '석식비율', '년', '첫_출근일', '국정감사'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0hGgdYCVak3w"},"source":["train_1.columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EYnfmPUVZ9fo"},"source":["train_2.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZxUks5YkZ9gs"},"source":["## Flaml Model"]},{"cell_type":"code","metadata":{"id":"OdrMVW_UZ9iE"},"source":["import numpy as np\n","import shap\n","def get_columns(model, X_test, train, del_col_nm='석식계'):\n","  explainer = shap.Explainer(model._model)\n","  shap_values = explainer(X_test)\n","  vals = np.abs(shap_values.values).mean(0)\n","  cols = list(train.columns)\n","  cols.remove(del_col_nm)\n","  feature_importance = pd.DataFrame(list(zip(cols, vals)), columns=['col_name','feature_importance_vals'])\n","  feature_importance.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)\n","  return feature_importance[feature_importance['feature_importance_vals'] > 1]['col_name'].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CIhoUcKEZ9jT"},"source":["from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler\n","\n","def run_kfold(train, test, selected_cols=[], target_col='중식계'):\n","    folds=KFold(n_splits=5, shuffle=True, random_state=2021)\n","    outcomes=[]\n","    model = None\n","    sub=[]\n","\n","    # X = None\n","    # X_test = None\n","    # if len(selected_cols) > 0:\n","    #   X = np.array(train[selected_cols])\n","    #   X_test = np.array(test[selected_cols])\n","    # else:\n","    #   X = np.array(train.drop(columns=[target_col]))\n","    #   cols = list(train.columns)\n","    #   cols.remove(target_col)\n","    #   X_test = np.array(test[cols])\n","\n","    # y = np.array(train[target_col])\n","    X = np.array(train.drop(columns=[target_col]))\n","    cols = list(train.columns)\n","    cols.remove(target_col)\n","    X_test = np.array(test[cols])\n","    y = np.array(train[target_col])\n","\n","    # 정규화\n","    standardScaler = StandardScaler()\n","    standardScaler.fit(X)\n","    X = standardScaler.transform(X)\n","\n","    X_test = standardScaler.transform(X_test) # 정규화\n","    cols_import = []\n","\n","    for n_fold, (train_index, val_index) in enumerate(folds.split(X)):\n","        print(n_fold, 'fold started =========================================')\n","        # X_train1, X_val = , X_train.loc[val_index]\n","        y_train = y[train_index]\n","        X_train = X[train_index]\n","        # y_train1, y_val = y_train.loc[train_index], y_train.loc[val_index]\n","        y_val = y[val_index]\n","        X_val = X[val_index]\n","        if n_fold == 0:\n","          automl = AutoML()\n","          automl_settings = {\n","              \"time_budget\": 120,  # in seconds\n","              \"metric\": 'mae',\n","              \"task\": 'regression'\n","          }\n","          automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)\n","          model = automl.model\n","        else:\n","          model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n","                        eval_metric='mae', early_stopping_rounds=10) \n","        \n","        pred1 = model.predict(X_test)\n","        if len(selected_cols) == 0:\n","          cols_import += list(get_columns(model, X_test, train=train, del_col_nm=target_col))\n","        sub.append(pred1)\n","    return sub, model, X_test, set(cols_import)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zh2He8lpZ9kS"},"source":["my_submission, model, X_test, cols_import = run_kfold(train_1, test, selected_cols=[], target_col='중식계')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_rTHcIwZ9lQ"},"source":["pred1 = np.mean(my_submission, axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jAuWxBBpZ9mX"},"source":["my_submission, model, X_test, cols_import = run_kfold(train_2, test, selected_cols=[], target_col='석식계')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ennetTR9Z9nX"},"source":["pred2 = np.mean(my_submission, axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kn1DpKi6Z9oa"},"source":["## Submission"]},{"cell_type":"code","metadata":{"id":"ZOUJomw-Z9pZ"},"source":["sample_submission = pd.read_csv(path+'sample_submission.csv')\n","submission = sample_submission.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sFKwBhwVZ9qr"},"source":["submission['중식계'] = pred1\n","submission['석식계'] = pred2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-1z51umTZ9r_"},"source":["from datetime import datetime\n","now_tm = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')\n","\n","sub_path = '/content/drive/MyDrive/DACON/Dacon_Industry_Meal/submit/'\n","submission.to_csv(sub_path+now_tm+'.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3ZtTz_ZCZ9tF"},"source":["## DACON API"]},{"cell_type":"code","metadata":{"id":"Og-hTSAYbWS9"},"source":["!pip install /content/drive/MyDrive/구내식당/water/dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i23RfqxAbYVY"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","'/content/drive/MyDrive/DACON/Dacon_Industry_Meal/submit/2021-07-22-02:37:54.csv', \n","'c7eb6960dc46f188d012c09ac2fbde1a0f90af05eeef92249719473834bb981e', \n","'235743', \n","'datu', \n","'optuna')"],"execution_count":null,"outputs":[]}]}