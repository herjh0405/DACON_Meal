{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LH_Dinner.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WJxt7Gh85Dztj0CiP8-zneepeNP_dL5o",
      "authorship_tag": "ABX9TyMKZ7D4Wt0pWH+pJ9wjEQ1E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/herjh0405/DACON_Meal/blob/master/LH_Dinner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CAkprrLcYzc"
      },
      "source": [
        "!pip install pycaret\n",
        "!pip install kaggler\n",
        "!pip install pendulum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh2U1L-BccNN"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "np.random.seed(0)\n",
        "\n",
        "from pycaret.regression import *\n",
        "from kaggler.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import os, re\n",
        "import glob\n",
        "import calendar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFI3RUD6cdCq"
      },
      "source": [
        "# 한글 폰트 사용\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import os\n",
        "\n",
        "def change_matplotlib_font(font_download_url):\n",
        "    FONT_PATH = 'MY_FONT'\n",
        "    \n",
        "    font_download_cmd = f\"wget {font_download_url} -O {FONT_PATH}.zip\"\n",
        "    unzip_cmd = f\"unzip -o {FONT_PATH}.zip -d {FONT_PATH}\"\n",
        "    os.system(font_download_cmd)\n",
        "    os.system(unzip_cmd)\n",
        "    \n",
        "    font_files = fm.findSystemFonts(fontpaths=FONT_PATH)\n",
        "    for font_file in font_files:\n",
        "        fm.fontManager.addfont(font_file)\n",
        "\n",
        "    font_name = fm.FontProperties(fname=font_files[0]).get_name()\n",
        "    matplotlib.rc('font', family=font_name)\n",
        "    print(\"font family: \", plt.rcParams['font.family'])\n",
        "\n",
        "font_download_url = \"https://fonts.google.com/download?family=Noto%20Sans%20KR\"\n",
        "change_matplotlib_font(font_download_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO0t5LcPcdm2"
      },
      "source": [
        "path = '/content/drive/MyDrive/구내식당/water/'\n",
        "train = pd.read_csv(path+'train.csv')\n",
        "test = pd.read_csv(path+'test.csv')\n",
        "holiday = pd.read_csv(path+'holidays.csv', index_col=0)\n",
        "corona = pd.read_csv(path+'corona_data.csv')\n",
        "\n",
        "df = pd.concat([train, test])\n",
        "df = df.fillna(0)\n",
        "df.columns = ['일자', '요일', '정원','휴가자', '출장자', '야근자',\\\n",
        "                 '재택근무자', '조식', '중식', '석식', '중식계', '석식계']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRJgdkRbceu5"
      },
      "source": [
        "df = df.drop(columns=['조식', '중식', '중식계'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ya0CyWrcgfk"
      },
      "source": [
        "dust_dir = os.path.join(path, '미세먼지_일별')\n",
        "wdata_dir = os.path.join(path, '날씨_시간별')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seanL06oc4zR"
      },
      "source": [
        "w_attrs = ['강수', '기온', '습도', '강수형태']\n",
        "w_years = os.listdir(wdata_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en6QMtDhdOvX"
      },
      "source": [
        "def get_wdata(data_path, dtype='num'):\n",
        "  datetime_list = []\n",
        "  value_list_12 = []\n",
        "  value_list_18 = []\n",
        "  curr_mon = ''\n",
        "\n",
        "  with open(data_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for i, line in enumerate(lines):\n",
        "      if line.strip() == '':\n",
        "        break\n",
        "      row_data = line.strip().split(',')\n",
        "      row_data = [elem.strip() for elem in row_data]\n",
        "      if i == 0:\n",
        "        curr_mon = row_data[-1].split()[-1][:-2]\n",
        "        continue\n",
        "      if len(row_data) == 1:\n",
        "        curr_mon = row_data[-1].split()[-1][:-2]\n",
        "        continue\n",
        "      r_day, r_hour, r_value = row_data\n",
        "      if r_hour in [\"1200\", \"1800\"]: # 점심 12시, 저녁 6시 기준으로 처리\n",
        "        if r_hour == \"1200\":\n",
        "          datetime_list.append(curr_mon[:4]+'-'+curr_mon[4:]+'-'+str('%02d'%int(r_day)))\n",
        "\n",
        "        if dtype == 'num':\n",
        "          if r_hour == \"1200\":\n",
        "            value_list_12.append(float(r_value))\n",
        "          else:\n",
        "            value_list_18.append(float(r_value))\n",
        "        else:\n",
        "          if r_hour == \"1200\":\n",
        "            value_list_12.append(str(round(float(r_value))))\n",
        "          else:\n",
        "            value_list_18.append(str(round(float(r_value))))\n",
        "          \n",
        "\n",
        "  return datetime_list, value_list_12, value_list_18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBoIbl1idPS6"
      },
      "source": [
        "# 강수, 기온, 습도, 강수형태 데이터\n",
        "w_data_rain_12 = []\n",
        "w_data_temp_12 = []\n",
        "w_data_hum_12 = []\n",
        "w_data_rtype_12 = []\n",
        "w_data_rain_18 = []\n",
        "w_data_temp_18 = []\n",
        "w_data_hum_18 = []\n",
        "w_data_rtype_18 = []\n",
        "w_datetime = []\n",
        "\n",
        "for year in w_years:\n",
        "  w_subdir = os.path.join(wdata_dir, year)\n",
        "  file_names = os.listdir(w_subdir)\n",
        "  file_name = \"\"\n",
        "  if year != '2021':\n",
        "    file_name = f'{year}01_{year}12.csv'\n",
        "  else:\n",
        "    file_name = f'{year}01_{year}04.csv'\n",
        "  file_path_rain = os.path.join(w_subdir, '충무공동_강수_'+file_name)\n",
        "  file_path_temp = os.path.join(w_subdir, '충무공동_기온_'+file_name)\n",
        "  file_path_hum = os.path.join(w_subdir, '충무공동_습도_'+file_name)\n",
        "  file_path_rtype = os.path.join(w_subdir, '충무공동_강수형태_'+file_name)\n",
        "\n",
        "  datetime_list_rain, value_list_rain_12, value_list_rain_18 = get_wdata(file_path_rain, dtype='num') # 강수 데이터\n",
        "  datetime_list_temp, value_list_temp_12, value_list_temp_18 = get_wdata(file_path_temp, dtype='num') # 기온 데이터\n",
        "  datetime_list_hum, value_list_hum_12, value_list_hum_18 = get_wdata(file_path_hum, dtype='num') # 습도 데이터\n",
        "  datetime_list_rtype, value_list_rtype_12, value_list_rtype_18 = get_wdata(file_path_rtype, dtype='cat') # 강수형태 데이터\n",
        "  \n",
        "  w_datetime   += datetime_list_rain\n",
        "  w_data_rain_12  += value_list_rain_12\n",
        "  w_data_temp_12  += value_list_temp_12\n",
        "  w_data_hum_12   += value_list_hum_12\n",
        "  w_data_rtype_12 += value_list_rtype_12\n",
        "  w_data_rain_18  += value_list_rain_18\n",
        "  w_data_temp_18  += value_list_temp_18\n",
        "  w_data_hum_18   += value_list_hum_18\n",
        "  w_data_rtype_18 += value_list_rtype_18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn8anQlbdQOz"
      },
      "source": [
        "w_df = pd.DataFrame({'일자':pd.Series(w_datetime, dtype='str'),\n",
        "                   'rain_lunch':pd.Series(w_data_rain_12, dtype='float'),\n",
        "                   'temp_lunch':pd.Series(w_data_temp_12, dtype='float'),\n",
        "                   'hum_lunch':pd.Series(w_data_hum_12, dtype='float'),\n",
        "                   'rain_type_lunch':pd.Series(w_data_rtype_12, dtype='str'),\n",
        "                   'rain_dinner':pd.Series(w_data_rain_18, dtype='float'),\n",
        "                   'temp_dinner':pd.Series(w_data_temp_18, dtype='float'),\n",
        "                   'hum_dinner':pd.Series(w_data_hum_18, dtype='float'),\n",
        "                   'rain_type_dinner':pd.Series(w_data_rtype_18, dtype='str')})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l4VXup7dQ6P"
      },
      "source": [
        "# 불쾌지수 컬럼 추가\n",
        "# https://dacon.io/competitions/official/235736/codeshare/2753?page=1&dtype=recent\n",
        "w_df['discomfort_index_lunch'] = 1.8*w_df['temp_lunch'] - 0.55*(1-w_df['hum_lunch']/100)*(1.8*w_df['temp_lunch']-26) + 32\n",
        "w_df['discomfort_index_dinner'] = 1.8*w_df['temp_dinner'] - 0.55*(1-w_df['hum_dinner']/100)*(1.8*w_df['temp_dinner']-26) + 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg1Noxc9dRnK"
      },
      "source": [
        "dust_file_paths = glob.glob(os.path.join(dust_dir, '*.xls'))\n",
        "d_datetime = []\n",
        "d_value1 = []\n",
        "d_value2 = []\n",
        "\n",
        "# 시간별 데이터의 경우 미세먼지 측정값 중 빈 값이 있는 경우가 어느 정도 있어서 배제했습니다.\n",
        "for file_path in dust_file_paths:\n",
        "  date_yyyymm = os.path.splitext(os.path.basename(file_path))[0] # yyyymm\n",
        "  date_year = date_yyyymm[:4]\n",
        "  date_mon = date_yyyymm[4:]\n",
        "  dust_df = None\n",
        "\n",
        "  if date_year == '2021':\n",
        "    dust_df = pd.read_excel(file_path, header=[0, 1], skiprows=3)\n",
        "  else:\n",
        "    dust_df = pd.read_excel(file_path, header=[0, 1])\n",
        "  cols = dust_df.columns\n",
        "  date_col = cols[0]\n",
        "  fine_dust_col = cols[1] # 미세먼지\n",
        "  ufine_dust_col = cols[2] # 초미세먼지\n",
        "\n",
        "  # 해당월의 일수 가져오기\n",
        "  days = calendar.monthrange(int(date_year),int(date_mon))[1] \n",
        "  for day in range(1, days+1):\n",
        "    day_1 = '%02d'%day\n",
        "    curr_day_df =  date_year+ '-' + date_mon + '-' + day_1\n",
        "\n",
        "    row_lunch = dust_df[dust_df[cols[0]] == curr_day_df]\n",
        "    row_dinner = dust_df[dust_df[cols[0]] == curr_day_df]\n",
        "    curr_date = date_year+'-'+date_mon+'-'+day_1\n",
        "  \n",
        "    d_datetime.append(curr_date)\n",
        "    d_value1.append(row_lunch[fine_dust_col].values[0])\n",
        "    d_value2.append(row_lunch[ufine_dust_col].values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyGzBahadSnr"
      },
      "source": [
        "dust_df = pd.DataFrame({'일자':pd.Series(d_datetime, dtype='str'),\n",
        "                   'fine_dust':pd.Series(d_value1, dtype='float'),\n",
        "                   'ultra_fine_dust':pd.Series(d_value2, dtype='float')})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wufnTZgndTXH"
      },
      "source": [
        "df = pd.merge(df, dust_df, on='일자')\n",
        "df = pd.merge(df, w_df, on='일자')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLfH0o5YdT93"
      },
      "source": [
        "df['fine_dust'][564, 1129] = [36, 23]\n",
        "df['ultra_fine_dust'][234, 235, 564, 654, 1129] = [11, 31, 26, 5, 9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJUIy-HvdUjS"
      },
      "source": [
        "df = df.drop(columns=['rain_lunch', 'temp_lunch', 'hum_lunch', 'rain_type_lunch', 'discomfort_index_lunch'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgzOo-hqdXF0"
      },
      "source": [
        "df['일자'] = pd.to_datetime(df['일자'])\n",
        "df['년'] = df['일자'].dt.year\n",
        "df['월'] = df['일자'].dt.month\n",
        "df['일'] = df['일자'].dt.day"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un0WtogrdYUF"
      },
      "source": [
        "holiday['date'] = pd.to_datetime(holiday['date'])\n",
        "df['before_holiday'] = df['일자'].apply(lambda x : 1 if (x+dt.timedelta(1) in holiday['date'].tolist()) else 0)\n",
        "df['after_holiday'] = df['일자'].apply(lambda x : 1 if (x-dt.timedelta(1) in holiday['date'].tolist()) else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClzIkmvodkmw"
      },
      "source": [
        "df['요일'] = df['일자'].dt.weekday\n",
        "df['야근_가능'] = df['요일'].apply(lambda x : 1 if (x==2) or (x==4) else 0)\n",
        "df['출근인원'] = df['정원']-(df['휴가자']+df['출장자']+df['재택근무자'])\n",
        "df['휴가비율'] = df['휴가자']/df['정원']\n",
        "df['출장비율'] = df['출장자']/df['정원']\n",
        "df['야근비율'] = df['야근자']/df['출근인원']\n",
        "df['재택비율'] = df['재택근무자']/df['정원']\n",
        "month_to_season = {1: 3,2: 3,3:0,4:0,5:0,6:1,7:1,8:1,9:2,10:2,11:2,12: 3}\n",
        "df['계절'] = df['월'].apply(lambda x : month_to_season[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByfN1dNfdnr-"
      },
      "source": [
        "import pendulum\n",
        "\n",
        "train = df.iloc[:train.shape[0],:] \n",
        "test = df.iloc[train.shape[0]:,:]\n",
        "train['주차'] = train['일자'].apply(lambda x: pendulum.parse(str(x)).week_of_month)\n",
        "test['주차'] = test['일자'].apply(lambda x: pendulum.parse(str(x)).week_of_month)\n",
        "\n",
        "repair_2017 = train[(train['년']==2017)&(train['주차']<0)]['일자'].dt.week\n",
        "repair_2021 = train[(train['년']==2021)&(train['주차']<0)]['일자'].dt.week\n",
        "test_repair = test[(test['년']==2021)&(test['주차']<0)]['일자'].dt.week\n",
        "\n",
        "train['주차'][list(repair_2017.index)] = repair_2017.values\n",
        "train['주차'][list(repair_2021.index)] = repair_2021.values\n",
        "test['주차'][list(test_repair.index)] = test_repair.values\n",
        "train['주차'][list(train[train['주차']==-46].index)] = np.array([6, 6, 6])\n",
        "\n",
        "df = pd.concat([train, test])\n",
        "df['출장자제외'] = df['정원'] - df['출장자']\n",
        "df['재택근무제외'] = df['정원'] - df['재택근무자']\n",
        "df['연기준몇일째']= df['일자'].dt.dayofyear\n",
        "df['연기준몇주째']= df['일자'].dt.weekofyear\n",
        "df['월일수']= df['일자'].dt.days_in_month\n",
        "df['윤년여부'] = df['일자'].dt.is_leap_year\n",
        "df['월시작일여부'] = df['일자'].dt.is_month_start\n",
        "df['월마지막일여부'] =df['일자'].dt.is_month_end\n",
        "df['분기시작일여부'] =df['일자'].dt.is_quarter_start\n",
        "df['분기마지막일여부'] =df['일자'].dt.is_quarter_end\n",
        "df['연시작일여부'] =df['일자'].dt.is_year_start\n",
        "df['연마지막일여부'] =df['일자'].dt.is_year_end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E5tiQmLdoYS"
      },
      "source": [
        "end_year = df[(df['월']==12)&(df['일']>=21)].index\n",
        "df['연말'] = df.apply(lambda x : 1 if  x.name in end_year else 0, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL95aYWqdpK9"
      },
      "source": [
        "corona['일자'] = pd.to_datetime(corona['일자'])\n",
        "corona = corona.drop_duplicates(['일자'])\n",
        "check_corona = corona[['일자', '누적검사자']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQTq88Ebdp2S"
      },
      "source": [
        "df = pd.merge(df,corona[['일자', '일일검사자']], on='일자', how='left')\n",
        "df = df.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-DcfLUtdqvz"
      },
      "source": [
        "# 이벤트\n",
        "event = pd.to_datetime(['2017-07-12', '2018-07-17', '2019-07-12', '2020-07-16'])\n",
        "df['이벤트'] = df['일자'].apply(lambda x : 1 if x in event else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLrnQwggdrXO"
      },
      "source": [
        "df = df.drop(columns=['석식'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkCHt1r1drzz"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "lbe = LabelEncoder()\n",
        "df[['년']] = lbe.fit_transform(df[['년']])\n",
        "onehot_col = ['요일', '계절']\n",
        "df = pd.concat([df[list((set(df.columns)-set(onehot_col)))],\\\n",
        "                pd.get_dummies(df[['요일', '계절']])], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM-QyA2kdycg"
      },
      "source": [
        "train = df.iloc[:train.shape[0], :]\n",
        "test = df.iloc[train.shape[0]:, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d6rJxsydy3a"
      },
      "source": [
        "train = train[train['석식계']!=0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iViepCm0d5bn"
      },
      "source": [
        "reg = setup(data=train,\n",
        "            target='석식계',\n",
        "            numeric_imputation = 'mean',\n",
        "            normalize = True,\n",
        "            silent= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0Sg5x0meA7P"
      },
      "source": [
        "best_5 = compare_models(sort='MAE', n_select=5)\n",
        "blended = blend_models(estimator_list= best_5, fold=5, optimize='MAE')\n",
        "pred_holdout = predict_model(blended)\n",
        "final_model = finalize_model(blended)\n",
        "pred1 = predict_model(final_model, test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21q8MfjEeDB6"
      },
      "source": [
        "sample_submission = pd.read_csv(path+'sample_submission.csv')\n",
        "submission = sample_submission.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkJoK7hOeEN1"
      },
      "source": [
        "submission['석식계'] = pred1.reset_index()['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW20nXCxeF3n"
      },
      "source": [
        "sub_path = '/content/drive/MyDrive/DACON/Dacon_Industry_Meal/submit/'\n",
        "best_submit = pd.read_csv(sub_path+'20210605_01_79.csv')\n",
        "df_82 = pd.read_csv(sub_path+'20210610_02_82.csv')\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "def show_mae(data) : \n",
        "    result = mean_absolute_error(best_submit['중식계'], data['중식계'])+mean_absolute_error(best_submit['석식계'], data['석식계'])\n",
        "    return display(result)\n",
        "\n",
        "show_mae(submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiiF_hKXeGvJ"
      },
      "source": [
        "mean_absolute_error(best_submit['석식계'], submission['석식계'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD9DMGkweJbU"
      },
      "source": [
        "submission = pd.read_csv(sub_path+'/20210614_01.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC1mPrVGeoGD"
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9MRRO2SeeAJ"
      },
      "source": [
        "submission['석식계'] = pred1.reset_index()['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdMKjVJReeyG"
      },
      "source": [
        "submission.to_csv(sub_path+'/20210614_01.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWYMYH-GejlR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}