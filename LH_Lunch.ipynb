{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LH_Lunch.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "yQYZdKJv-nPm",
        "FQowLejR_SD6",
        "c8lX6Sst_c8F",
        "LE_WTj5OCvsW"
      ],
      "mount_file_id": "1l2NH5yafpIojJ-f0dM0WEDv-rwEiHKNw",
      "authorship_tag": "ABX9TyMkafnZ8tNSy4QDWmuOlVvY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/herjh0405/DACON_Meal/blob/master/LH_Lunch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrP5riasfpzN"
      },
      "source": [
        "!pip install catboost\n",
        "!pip install pycaret\n",
        "!pip install kaggler\n",
        "!pip install pendulum\n",
        "!pip install flaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKXMNXLhfsoG"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "np.random.seed(0)\n",
        "\n",
        "from pycaret.regression import *\n",
        "from kaggler.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import os, re\n",
        "import glob\n",
        "import calendar\n",
        "\n",
        "from flaml import AutoML\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qUC3VbFfuP2"
      },
      "source": [
        "# 한글 폰트 사용\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import os\n",
        "\n",
        "def change_matplotlib_font(font_download_url):\n",
        "    FONT_PATH = 'MY_FONT'\n",
        "    \n",
        "    font_download_cmd = f\"wget {font_download_url} -O {FONT_PATH}.zip\"\n",
        "    unzip_cmd = f\"unzip -o {FONT_PATH}.zip -d {FONT_PATH}\"\n",
        "    os.system(font_download_cmd)\n",
        "    os.system(unzip_cmd)\n",
        "    \n",
        "    font_files = fm.findSystemFonts(fontpaths=FONT_PATH)\n",
        "    for font_file in font_files:\n",
        "        fm.fontManager.addfont(font_file)\n",
        "\n",
        "    font_name = fm.FontProperties(fname=font_files[2]).get_name()\n",
        "    matplotlib.rc('font', family=font_name)\n",
        "    print(\"font family: \", plt.rcParams['font.family'])\n",
        "\n",
        "font_download_url = \"https://fonts.google.com/download?family=Nanum%20Gothic\"\n",
        "change_matplotlib_font(font_download_url)\n",
        "# 마이너스 폰트 깨짐 방지\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3PKLkpn7Pmj"
      },
      "source": [
        "path = '/content/drive/MyDrive/구내식당/water/'\n",
        "train = pd.read_csv(path+'train.csv')\n",
        "test = pd.read_csv(path+'test.csv')\n",
        "holiday = pd.read_csv(path+'holidays.csv', index_col=0)\n",
        "corona = pd.read_csv(path+'corona_data.csv')\n",
        "\n",
        "df = pd.concat([train.iloc[:, :-2], test])\n",
        "target_df = train.iloc[:, -2:]\n",
        "df.columns = ['일자', '요일', '정원','휴가자', '출장자', '야근자',\\\n",
        "                 '재택근무자', '조식', '중식', '석식']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQYZdKJv-nPm"
      },
      "source": [
        "## 메뉴 관련 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ykDEFEb-1VI"
      },
      "source": [
        "# Menu-extracting function\n",
        "def extractMenu(array, keywords=[], not_in_keywords={}, comm_not_in=[]):\n",
        "  extractedMenu = []\n",
        "  for menu_nm in array:\n",
        "    for kw in keywords:\n",
        "      if menu_nm.find(kw) > -1:\n",
        "        has_not_in = False\n",
        "        if kw in not_in_keywords:\n",
        "          for sub_kw in not_in_keywords[kw]:\n",
        "            if menu_nm.find(sub_kw) > -1:\n",
        "              has_not_in = True\n",
        "              break\n",
        "        for sub_kw in comm_not_in:\n",
        "            if menu_nm.find(sub_kw) > -1:\n",
        "              has_not_in = True\n",
        "              break\n",
        "\n",
        "        if not has_not_in:\n",
        "          extractedMenu.append(menu_nm)\n",
        "          break\n",
        "  return(extractedMenu)\n",
        "\n",
        "def extractMenu2(array, keywords=[]):\n",
        "  extractedMenu = []\n",
        "  for menu_nm in tot_menu_arr:\n",
        "    for kw in keywords:\n",
        "      if menu_nm.find(kw) > -1:\n",
        "        menu_nm_list = re.split(r'[^\\w]', menu_nm)\n",
        "        for menu_nm_tmp in menu_nm_list:\n",
        "          if menu_nm_tmp.find(kw) + len(kw) == len(menu_nm_tmp): # 끝에 있으면\n",
        "            extractedMenu.append(menu_nm)\n",
        "        break\n",
        "  return(extractedMenu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MUhPAob-3kg"
      },
      "source": [
        "lunch_menu_data = df['중식']\n",
        "dinner_menu_data = df['석식']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61mXHJgI-3Sz"
      },
      "source": [
        "tot_menu_arr = []\n",
        "pattern = r\"\\(.*\\)\"\n",
        "for menu_data in [lunch_menu_data, dinner_menu_data]:\n",
        "  for daily_menu in menu_data:\n",
        "    menu_list = daily_menu.strip().split()\n",
        "    menu_list2 = []\n",
        "    for i, menu_nm in enumerate(menu_list):\n",
        "      menu_nm = re.sub(pattern, '', menu_nm)\n",
        "      if menu_nm.strip() in ['', '*']:\n",
        "        continue\n",
        "      if menu_nm[0] == '(' or menu_nm[-1] == ')':\n",
        "        continue\n",
        "      menu_list2.append(menu_nm)\n",
        "    tot_menu_arr += menu_list2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjBtsk_j-2xT"
      },
      "source": [
        "tot_menu_arr = set(tot_menu_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsTj9nrV--xG"
      },
      "source": [
        "len(tot_menu_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEjJtWFW--uV"
      },
      "source": [
        "# 육류 분류\n",
        "# 소고기\n",
        "# https://namu.wiki/w/%EC%87%A0%EA%B3%A0%EA%B8%B0\n",
        "beef = ['소고기', '쇠고기', '불고기', '떡갈비', '갈비찜', '소갈비', '육사시미', '육회', '장조림', '와규', '야키니쿠', '규동', '스테이크', '햄버그 스테이크',\n",
        " '함박스테이크', '함바그스테이크', '함박 스테이크', '햄버거', '로스트 디너', '비프가스밀라네사', '웰링턴', '슈하스쿠', '아사도', '우육면',\n",
        " '육개장', '육포', '평양냉면', '비프 스트로가노프', '설렁탕', '소고기국', '소머리국밥', '곰탕', '너비아니', '보르챠', '소꼬리']\n",
        "# 돼지고기\n",
        "# https://namu.wiki/w/%EB%8F%BC%EC%A7%80%EA%B3%A0%EA%B8%B0\n",
        "pig = ['돼지', '돼지머리', '머릿고기', '뒷고기', '관자살', '콧등살', '삼각살', '설중살', '설하살', '안중살', '뽈항정살',\n",
        " '볼살', '두항정', '돼지코', '항정살', '목살', '가브리살', '갈비', '앞다리살', '갈매기살', '등심', '안심',\n",
        " '삼겹살', '오겹살', '뒷다리살', '돈족', '내장', '오소리감투', '허파', '염통', '콩팥', '새끼보', '돈낭',\n",
        " '돈족', '돼지꼬리', '사태', '막창', '감자탕', '돈가스', '돼지갈비', '돼지국밥', '돼지불고기', '두루치기', '순대',\n",
        " '순댓', '족발', '보쌈', '수육', '편육', '제육', '탕수육', '삼겹', '맥적', '차슈', '향우구육', '꿔바로우', '훙사오러우',\n",
        " '회과육', '동파육', '라후테', '오향장육', '슈바인스학세', '소시지', '소세지', '포크 커틀릿', '함바그 스테이크', '함바그스테이크',\n",
        " '함박스테이크', '살스테이크','살 스테이크', '함박 스테이크', '베이컨', '햄', '스팸', '폭립', '폭찹', '돈지루', '부타동', '바쿠테', '팟 카파오 무 쌉', '비엔나', '소떡', '육']\n",
        "# 닭고기\n",
        "# https://namu.wiki/w/%EB%8B%AD%EA%B3%A0%EA%B8%B0\n",
        "chicken = ['닭', '깐풍기', '꼬꼬면', '궁보계정', '간장닭', '기스면', '계', '도빙무시', '라조기', '백숙', '영계백숙',\n",
        " '불닭', '삼계탕', '삼계선', '오니시메', '옻닭', '연팔기', '유린기', '육회', '좌종당계', '찜닭', '초계밀면',\n",
        " '치킨', '도리텐', '지파이', '치짜', '취계', '카라아게', '가라아', '파닭', '양파닭', '케밥', '코코뱅', '탕수기',\n",
        " '포계', '프랑구 아사두']\n",
        "# 양고기\n",
        "# https://namu.wiki/w/%EC%96%91%EA%B3%A0%EA%B8%B0\n",
        "sheep = ['양고기','훠궈', '양꼬치', '케밥', '샤슬릭', '징기스칸', '셰퍼드 파이', '허르헉', '양갈비']\n",
        "# 오리고기\n",
        "# https://namu.wiki/w/%EC%98%A4%EB%A6%AC%EA%B3%A0%EA%B8%B0\n",
        "dug = ['오리']\n",
        "\n",
        "web_keywords = beef + pig + chicken + sheep + dug\n",
        "keywords = ['돈까스', '히레카츠', '히레까쓰', '히레가스', '포크', '부대찌개', '뒷다리', '앞다리', '돈', '순살',\n",
        "                '소머리', '등뼈', '곱창', '도가니', '뼈해장국', '뼈다귀해장국', '목심', '채끝', '우둔', '양지', '설도', '만두', '만둣',\n",
        "                '잡채', '류산슬', '유산슬', '고기', '고깃']\n",
        "keywords += web_keywords\n",
        "\n",
        "not_in_keywords = {'오리':['아오리', '오리엔탈'], '계':['계란', '계발', '계피'], '장조림':['계란', '메추리알'], '치킨':['치킨무'], '돈':['돈나물'], '만두':['당면계란'], '만둣':['당면계란']}\n",
        "meat_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-I02EzT--qc"
      },
      "source": [
        "# 돼지고기\n",
        "keywords = ['돼지', '돼지머리', '머릿고기', '뒷고기', '관자살', '콧등살', '삼각살', '설중살', '설하살', '안중살', '뽈항정살',\n",
        " '볼살', '두항정', '돼지코', '항정살', '목살', '가브리살', '앞다리살', '갈매기살', '등심', '안심',\n",
        " '삼겹살', '오겹살', '앞다리살', '뒷다리살', '돈족', '내장', '오소리감투', '허파', '염통', '콩팥', '새끼보', '돈낭',\n",
        " '돈족', '돼지꼬리', '사태', '막창', '감자탕', '돈가스', '돼지갈비', '돼지국밥', '돼지불고기', '두루치기', '순대',\n",
        " '순댓', '족발', '보쌈', '수육', '편육', '제육', '탕수육', '삼겹', '맥적', '차슈', '향우구육', '꿔바로우', '훙사오러우',\n",
        " '회과육', '동파육', '라후테', '오향장육', '슈바인스학세', '소시지', '소세지', '포크 커틀릿',\n",
        " '목살스테이크','목살 스테이크', '베이컨', '햄', '스팸', '폭립', '폭찹', '돈지루', '부타동', '바쿠테', '팟 카파오 무 쌉', '비엔나', '소떡',\n",
        " '돈까스', '히레카츠', '히레까쓰', '히레가스', '포크', '돈', '등뼈', '뼈해장국', '뼈다귀해장국']\n",
        "not_in_keywords = {'돈':['돈나물'], '만두':['당면계란'], '만둣':['당면계란']}\n",
        "pig_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkndYkKF--mD"
      },
      "source": [
        "# 소고기\n",
        "keywords = ['소고기', '쇠고기', '소불고기', '소갈비', '육사시미', '육회', '와규', '야키니쿠', '규동', '소곱창',\n",
        "            '로스트 디너', '비프가스밀라네사', '웰링턴', '슈하스쿠', '아사도', '우육면',\n",
        "            '육개장', '육포', '평양냉면', '비프 스트로가노프', '설렁탕', '소고기국', '소머리국밥', '곰탕', '너비아니', '보르챠', '소꼬리', '소머리', '설도', '목심', '채끝', '우둔', '양지', '도가니']\n",
        "beef_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu5btCQl_ExN"
      },
      "source": [
        "# 닭고기\n",
        "keywords = ['닭', '깐풍기', '꼬꼬면', '궁보계정', '간장닭', '기스면', '계', '도빙무시', '라조기', '백숙', '영계백숙',\n",
        "          '불닭', '삼계탕', '삼계선', '오니시메', '옻닭', '연팔기', '유린기', '육회', '좌종당계', '찜닭', '초계밀면',\n",
        "          '치킨', '도리텐', '지파이', '치짜', '취계', '카라아게', '가라아', '파닭', '양파닭', '케밥', '코코뱅', '탕수기',\n",
        "          '포계', '프랑구 아사두']\n",
        "not_in_keywords = {'계':['계란', '계발', '계피'], '치킨':['치킨무']}\n",
        "\n",
        "chicken_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyBscZPX_Eq5"
      },
      "source": [
        "# 양고기 - 데이터 없어서 제외\n",
        "keywords = ['양고기','훠궈', '양꼬치', '케밥', '샤슬릭', '징기스칸', '셰퍼드 파이', '허르헉', '양갈비']\n",
        "sheep_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])\n",
        "sheep_menus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29errrks_Em8"
      },
      "source": [
        "# 오리고기\n",
        "keywords = ['오리']\n",
        "not_in_keywords = {'오리':['아오리', '오리엔탈']}\n",
        "duck_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIiPZsJq_Eik"
      },
      "source": [
        "#난류 (계란)\n",
        "keywords = ['계란', '난', '란', '메추리알', '날치알', '동태알']\n",
        "not_in_keywords = {\"란\":['토란'], '난':['커리', '카레']}\n",
        "egg_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCvsvlx8_Ed1"
      },
      "source": [
        "# 죽류\n",
        "keywords = ['죽', '누룽지']\n",
        "juk_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vfiEY18_EX2"
      },
      "source": [
        "# 덮밥 및 국밥류\n",
        "keywords = ['덮밥', '국밥']\n",
        "gukbob_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNL-w6Fm--hI"
      },
      "source": [
        "# 비빔밥 및 볶음밥류\n",
        "keywords = ['비빔밥', '볶음밥']\n",
        "bb_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i8uzCd2_NQ-"
      },
      "source": [
        "# 국탕류\n",
        "keywords = ['국', '탕', '찌개', '국물']\n",
        "soup_menus = extractMenu2(tot_menu_arr, keywords=keywords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJtEwngK_Ndc"
      },
      "source": [
        "# 구이류\n",
        "keywords = ['구이']\n",
        "gui_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx1ksLEc_NlR"
      },
      "source": [
        "# 전류\n",
        "keywords = ['전', '부침개', '빈대떡']\n",
        "jeon_menus = extractMenu2(tot_menu_arr, keywords=keywords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDXN4Jft_Nrt"
      },
      "source": [
        "# http://yaksik.net/detail.php?number=24904\n",
        "# 튀김류\n",
        "keywords = ['튀김', '까스', '카츠', '가츠', '까츠', '탕수', '덴뿌라', '덴푸라', '크로켓', '고로케', '맛탕', '치킨', '통닭', '부각', '강정', '김말이', '깐풍']\n",
        "fry_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQowLejR_SD6"
      },
      "source": [
        "## 메뉴 추가 특성 - Part1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCcKhNAJ_SAN"
      },
      "source": [
        "# 곡물\n",
        "keywords = ['현미', '밥', '쌀', '보리', '죽', '참깨', '들깨', '수수', '잡곡', '귀리', '퀴노아', '아마란스', '옥수수', '기장', '메밀', '모밀']\n",
        "grain_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxOcmQZV_R-G"
      },
      "source": [
        "# 콩류\n",
        "keywords = ['콩', '녹두', '팥', '완두']\n",
        "not_in_keywords = {'콩':['콩나물']}\n",
        "bean_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmqzkA84_R6d"
      },
      "source": [
        "# 묵\n",
        "keywords = ['묵']\n",
        "not_in_keywords = {'묵':['어묵', '묵은지']}\n",
        "kor_jelly_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQlE4n5R_R3D"
      },
      "source": [
        "# 생선 및 조개류\n",
        "# https://ko.wikipedia.org/wiki/%EC%83%9D%EC%84%A0\n",
        "# https://namu.wiki/w/%EC%83%9D%EC%84%A0\n",
        "# https://namu.wiki/w/%EC%A1%B0%EA%B0%9C\n",
        "keywords = ['생선', '조개', '메기', '송어', '오징어', '굴', '멸치', '숭어', '성게', '고등어', '명태',\n",
        "            '쏨뱅이', '연어', '틸라피아', '우럭', '이리치', '가재', '참바리', '상어', '돔',\n",
        "            '삼치', '방어', '참치', '새우', '문어', '홍어', '농어', '붉평치', '청상아리', '황새치',\n",
        "            '다랑어', '비막치어', '장어', '녹새치', '숭어', '굴비', '조기', '갈치', '꽁치',\n",
        "            '전어', '명태', '노가리', '황태', '은어', '가물치', '쏘가리', '붕어', '잉어', '모래마주', '가자미',\n",
        "            '간재미', '가오리', '박대', '양미리', '과메기', '청어', '생태',\n",
        "            '개복치', '광어', '넙치', '기름치', '까나리', '날치','놀래미'\n",
        "            ,'능성어','달고기','대구','도다리','도루묵','도미','독가시치'\n",
        "            ,'만새기','망상어','문절망둑','물메기','미꾸라지','민어','방어'\n",
        "            ,'추어탕','배스','밴댕이','뱅어','벵에돔','병어','보리멸'\n",
        "            ,'복어','볼락','부세','부시리','붕장어','블루길'\n",
        "            ,'빙어','산천어','서대','시샤모','쏘가리','쏠배감펭','쏨뱅이'\n",
        "            ,'아귀','아구','임연수','전갱이','전복치','점성어','정어리'\n",
        "            ,'준치','쥐치','청새치','청어','향어','홍어','황새치','매운탕'\n",
        "            ,'루테피스크','게맛살','물회','회덮밥','부야베스','북엇국','세꼬시','수르스트뢰밍','식해','어묵','오뎅'\n",
        "            ,'쥐포','추어탕','피시 앤드 칩스','피쉬 앤드 칩스','피시앤드칩스','피쉬앤드칩스','피시앤칩스','피쉬앤칩스','해물'\n",
        "            ,'가리비', '개오지', '꼬막','대칭이','바지락','백합','홍합','소라', '골뱅이', '고둥','재첩'\n",
        "            ,'전복','플라티케라무스', '봉골레', '클램차우더']\n",
        "not_in_keywords = {'굴':['굴소스'], '새우':['새우젓']}\n",
        "fish_shell_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAKGLplP_R07"
      },
      "source": [
        "# 채소류\n",
        "# https://namu.wiki/w/%EC%B1%84%EC%86%8C?from=%EC%95%BC%EC%B1%84\n",
        "keywords = ['가지', '갓', '감자', '고구마', '고사리', '고추', '페페론치노', '냉이', '근대', '깻잎', '차조기'\n",
        "            , '당근', '더덕', '도라지', '동아', '딸기', '마', '마늘', '멜론', '무', '무청'\n",
        "            , '바나나', '배추', '버섯', '부추', '브로콜리', '상추', '생강', '쇠비름', '나물'\n",
        "            , '쑥', '시금치', '수박', '시호', '아스파라거스', '야콘', '양파', '여주', '연근', '열무', '오이'\n",
        "            , '우엉', '인삼', '죽순', '청경채', '참외', '칡', '풋콩', '토란', '토마토', '쪽파', '대파', '파인애플'\n",
        "            , '파프리카', '피망', '케일', '고수', '로즈마리', '루타바가', '바질', '박하', '산마늘', '셀러리'\n",
        "            , '아티초크', '타임', '파슬리', '호박', '피클', '파채', '파김치', '채소', '야채']\n",
        "not_in_keywords = {'무':['무침'], '마':'마카로니', '고추':['고추장']}\n",
        "vegetable_menus =  extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajuoyOO9_RxJ"
      },
      "source": [
        "# 해조류\n",
        "# https://namu.wiki/w/%EC%A1%B0%EB%A5%98(%EC%88%98%EC%A4%91%EC%83%9D%EB%AC%BC)?from=%ED%95%B4%EC%A1%B0%EB%A5%98\n",
        "keywords = ['김', '우뭇가사리', '한천', '매생이', '파래', '바다포도', '해캄', '클로렐라', '청각', '마리모모스볼', '다시마', '미역', '감태', '톳']\n",
        "not_in_keywords = {'김':['김치', '튀김', '김칫']}\n",
        "sea_alg_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2tDD97z_Rtq"
      },
      "source": [
        "# 쌀케익 - 없어서 패스"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB4-DOpW_RrS"
      },
      "source": [
        "# 발효된 콩 상품 -> 장류\n",
        "# https://namu.wiki/w/%EC%9E%A5%EB%A5%98\n",
        "keywords = ['된장', '간장', '쯔유', '노추', '미소', '고추장', '청국장', '담북장', '팥장', '두부장', '비지장', '어육장', '춘장', '마장', '낫토', '두반장', '해선장', '굴소스', '게장',\n",
        " '장조림', '양념장', '장국', '쌈장', '초장', '*장']\n",
        "jang_menus  = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE6zUsAp_Ro6"
      },
      "source": [
        "# 김치\n",
        "# https://namu.wiki/w/%EA%B9%80%EC%B9%98\n",
        "keywords = ['김치', '깍두기', '석박지', '동치미', '겉절이', '묵은지', '소박이', '섞박지', '생채', '게국지', '김칫']\n",
        "kimchi_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c1XH9S7_Rmf"
      },
      "source": [
        "# 만두\n",
        "# https://namu.wiki/w/%EB%A7%8C%EB%91%90\n",
        "keywords = ['만두', '춘권', '만쥬', '사모사', '만둣']\n",
        "mandu_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords={}, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCwa_vM6_cs9"
      },
      "source": [
        "# 곡물 가루(밀가루, 쌀가루 등 전분)\n",
        "# https://namu.wiki/w/%EB%B0%80%EA%B0%80%EB%A3%A8\n",
        "# 미숫가루\n",
        "keywords = [\"면\", \"수제비\", \"전\", \"부침개\", \"빵\", \"춘권\", \"튀김\", \"과자\", \"국수\", \"메밀\", \"모밀\", \"피자\", \"전병\", \"떡\", \"어묵\", \"오뎅\", \"소시지\", \"소세지\", \"햄\", \"김밥\", \n",
        "            \"부대찌개\", \"스콘\", \"만두\", \"파이\", \"빈대떡\", \"케이크\", \"케익\", \"쿠키\", \"핫도그\", \"파스타\", \"치킨\", \"라자냐\", \"팟타이\", \"나쵸\", \"팝콘\", '스파게티', '짬뽕']\n",
        "not_in_keywords = {'치킨':['치킨무'], '전':['전주식'], '짬뽕':['고기', '찌개', '국']}\n",
        "powder_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXRc_I7B_c4Y"
      },
      "source": [
        "# 과일\n",
        "# https://namu.wiki/w/%EA%B3%BC%EC%9D%BC\n",
        "# https://namu.wiki/w/%EC%88%98%EC%9E%85%20%EA%B3%BC%EC%9D%BC\n",
        "keywords = ['구기자','매실','무화과','버찌','체리','복분자','복숭아','블랙베리','블루베리','딸기','살구','앵두','자두','포도'\n",
        "            ,'감','다래','대추','머루','모과','무화과','배','사과','석류','으름','귤','유자','레드향','천혜향','한라봉'\n",
        "            ,'과라나','구아바','구즈베리','토마토','나랑히야','노니','노팔','니파팜','두꾸','두리안','라임','람부탄'\n",
        "            ,'레몬','애플','루비솔트부쉬','리치','여지','마랑','마룰라','마르멜로','마프랑','망고','블랙베리','아보카도'\n",
        "            ,'아로니아','아사이베리','아사이 베리','양초열매','오렌지','올리브','용안','롱간','자몽','바나나','딸기','수박'\n",
        "            ,'참외','멜론','메론','여주','파인애플','토마토','코코넛','크랜베리','타마린드','파파야','패션프루트','패션후르츠']\n",
        "not_in_keywords = {'살구':['구이', '목살', '삼겹살', '가브리살', '갈비살', '항정살'], '감':['감자'], '배':['배추', '알배기', '소배기']}\n",
        "comm_not_in = ['주스', '쥬스', '음료', 'D', '순']\n",
        "fruit_menus = extractMenu(tot_menu_arr, keywords=keywords, not_in_keywords=not_in_keywords, comm_not_in=comm_not_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8lX6Sst_c8F"
      },
      "source": [
        "## 메뉴 추가 특성 - Part2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V-tLXEM_c_v"
      },
      "source": [
        "# 쌀\n",
        "# https://namu.wiki/w/%EA%B3%A1%EB%AC%BC\n",
        "\n",
        "keywords = ['쌀', '잡곡', '오곡', '현미', '흑미', '귀리', '차조', '렌틸콩', '강낭콩', '병아리콩', '완두콩', '기장', '보리', '수수', '호밀'] \n",
        "not_in_keywords = {'쌀':['쌀국수', '찹쌀'], '기장':['장조림'], '수수':['옥수수', '부꾸미']} # 찹쌀은 밥 메뉴명에 쓰이지 않아 삭제\n",
        "comm_not_in = ['스프']\n",
        "rice_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er5kRW4h_dCS"
      },
      "source": [
        "# 김밥 및 초밥\n",
        "\n",
        "keywords = ['김밥', '초밥'] \n",
        "not_in_keywords = {'김밥':['볶음밥']}\n",
        "comm_not_in = []\n",
        "gimbab_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYnsISbF_dGS"
      },
      "source": [
        "# 소금, 식초 등에 절인 해산물\n",
        "# 해산물이 들어있지 않은 절임류도 포함시킴\n",
        "\n",
        "keywords = ['절임', '젓'] \n",
        "not_in_keywords = {}\n",
        "comm_not_in = []\n",
        "saused_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCIwG9SL_dHy"
      },
      "source": [
        "# 면류\n",
        "# https://femiwiki.com/w/%EB%B6%84%EB%A5%98:%EC%A2%85%EB%A5%98/%EB%A9%B4%EC%9A%94%EB%A6%AC\n",
        "keywords = ['국수', '면', '파스타', '스파게티', '짬뽕', '라면'] \n",
        "not_in_keywords = {'짬뽕':['고기', '찌개', '국']}\n",
        "comm_not_in = []\n",
        "noodle_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryTAAXbf_dKh"
      },
      "source": [
        "# 스튜 - 조림과 찌개의 중간단계\n",
        "# https://namu.wiki/w/%EC%8A%A4%ED%8A%9C\n",
        "keywords = ['스튜', '조림'] \n",
        "not_in_keywords = {}\n",
        "comm_not_in = []\n",
        "stew_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFCcLTq5_dNi"
      },
      "source": [
        "# 한국 전통 샐러드\n",
        "keywords = ['나물', '무침'] \n",
        "not_in_keywords = {'나물':['콩나물', '밥']}\n",
        "comm_not_in = []\n",
        "namul_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FadGmqSj_dPu"
      },
      "source": [
        "# 피클\n",
        "keywords = ['피클'] \n",
        "not_in_keywords = {}\n",
        "comm_not_in = []\n",
        "pickle_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2EvAh24_dSH"
      },
      "source": [
        "# 뚝배기 - 없음 -> 제외\n",
        "keywords = ['뚝배기', '돌솥'] \n",
        "not_in_keywords = {}\n",
        "comm_not_in = []\n",
        "dduk_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)\n",
        "\n",
        "dduk_menus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61i-6POx_dV8"
      },
      "source": [
        "# 샐러드\n",
        "keywords = ['샐러드'] \n",
        "not_in_keywords = {}\n",
        "comm_not_in = []\n",
        "salad_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa9wDbZ3_dX_"
      },
      "source": [
        "# 우유\n",
        "# 우유가 들어간 식재료(크림, 요거트 등)종류로 변경\n",
        "keywords = ['까르보나라', '크림', '요거트'] \n",
        "not_in_keywords = {}\n",
        "comm_not_in = ['샐러드', 'D', '드레싱', '소스'] # 샐러드 드레싱, 디핑소스 제외\n",
        "milk_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjyIqm7P_daU"
      },
      "source": [
        "# 빵, 쿠키\n",
        "# https://ko.wikipedia.org/wiki/%EB%B9%B5_%EB%AA%A9%EB%A1%9D\n",
        "keywords = ['와플', '케이크', '케잌', '바게트', '도넛', '도너츠', '핫도그', '도라야키', '베이글', '번', '비스킷', '스콘', '토스트', '브레드', '포카차', '피자', '호두과자', '쿠키'] \n",
        "not_in_keywords = {}\n",
        "comm_not_in = []\n",
        "bread_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmnB-rio_qz0"
      },
      "source": [
        "# 음료\n",
        "# https://ko.wikipedia.org/wiki/%EB%B9%B5_%EB%AA%A9%EB%A1%9D\n",
        "keywords = ['주스', '쥬스', '수정과', '식혜', '식초', '코코아', '칵테일', '스무디', '우유', '셰이크', '야쿠르트', '요구르트', '커피', '차', '탄산수', '음료'] \n",
        "not_in_keywords = {'차':['차돌']}\n",
        "comm_not_in = []\n",
        "drink_menus = extractMenu(tot_menu_arr, keywords, not_in_keywords, comm_not_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLFMSNCz_q2V"
      },
      "source": [
        "def get_food_one_hot(x, menu_array):\n",
        "  menu_list = x.strip().split()\n",
        "  for i, menu_nm in enumerate(menu_list):\n",
        "    menu_nm = re.sub(pattern, '', menu_nm)\n",
        "    if menu_nm.strip() in ['', '*']:\n",
        "      continue\n",
        "    if menu_nm[0] == '(' or menu_nm[-1] == ')':\n",
        "      continue\n",
        "    try:\n",
        "      if menu_array.index(menu_nm) > -1:\n",
        "        return 1\n",
        "    except Exception:\n",
        "      pass\n",
        "  return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whUqZvnZ_q4k"
      },
      "source": [
        "# 데이터 병합\n",
        "menu_col_nm = ['육류', '난류', '죽류', '덮밥_국밥류', '비빔밥_볶음밥류', '국탕류', '구이류', '전류', '튀김류', '곡물', '콩류',\n",
        "               '묵', '생선_조개류', '채소류', '해조류', '장류', '김치', '만두', '곡물가루', '과일', '쌀', '김밥_초밥', '절임류',\n",
        "               '면류', '스튜', '나물_무침류', '피클', '샐러드', '우유', '빵류', '음료', '돼지고기', '소고기', '닭고기', '오리고기']\n",
        "menu_data_arr = [meat_menus, egg_menus, juk_menus, gukbob_menus, bb_menus, soup_menus, gui_menus, jeon_menus, fry_menus, grain_menus, bean_menus,\n",
        "                 kor_jelly_menus, fish_shell_menus, vegetable_menus, sea_alg_menus, jang_menus, kimchi_menus, mandu_menus, powder_menus, fruit_menus, rice_menus, gimbab_menus, saused_menus,\n",
        "                 noodle_menus, stew_menus, namul_menus, pickle_menus, salad_menus, milk_menus, bread_menus, drink_menus, pig_menus, beef_menus, chicken_menus, duck_menus]\n",
        "\n",
        "for col_type in ['중식메뉴', '석식메뉴']:\n",
        "  for i, menu_arr in enumerate(menu_data_arr):\n",
        "    train[col_type + '_' + menu_col_nm[i]] = train[col_type].apply(lambda x: get_food_one_hot(x, menu_arr))\n",
        "    test[col_type + '_' + menu_col_nm[i]] = train[col_type].apply(lambda x: get_food_one_hot(x, menu_arr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgtDxinW_Nv5"
      },
      "source": [
        "df = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
        "df = df.fillna(0)\n",
        "df.columns = ['일자', '요일', '정원', '휴가자', '출장자', '야근자', '재택근무자', '조식', '중식', '석식',\\\n",
        "              '중식계', '석식계', '중식메뉴_육류',\n",
        "       '중식메뉴_난류', '중식메뉴_죽류', '중식메뉴_덮밥_국밥류', '중식메뉴_비빔밥_볶음밥류', '중식메뉴_국탕류',\n",
        "       '중식메뉴_구이류', '중식메뉴_전류', '중식메뉴_튀김류', '중식메뉴_곡물', '중식메뉴_콩류', '중식메뉴_묵',\n",
        "       '중식메뉴_생선_조개류', '중식메뉴_채소류', '중식메뉴_해조류', '중식메뉴_장류', '중식메뉴_김치', '중식메뉴_만두',\n",
        "       '중식메뉴_곡물가루', '중식메뉴_과일', '중식메뉴_쌀', '중식메뉴_김밥_초밥', '중식메뉴_절임류', '중식메뉴_면류',\n",
        "       '중식메뉴_스튜', '중식메뉴_나물_무침류', '중식메뉴_피클', '중식메뉴_샐러드', '중식메뉴_우유', '중식메뉴_빵류',\n",
        "       '중식메뉴_음료', '중식메뉴_돼지고기', '중식메뉴_소고기', '중식메뉴_닭고기', '중식메뉴_오리고기', '석식메뉴_육류',\n",
        "       '석식메뉴_난류', '석식메뉴_죽류', '석식메뉴_덮밥_국밥류', '석식메뉴_비빔밥_볶음밥류', '석식메뉴_국탕류',\n",
        "       '석식메뉴_구이류', '석식메뉴_전류', '석식메뉴_튀김류', '석식메뉴_곡물', '석식메뉴_콩류', '석식메뉴_묵',\n",
        "       '석식메뉴_생선_조개류', '석식메뉴_채소류', '석식메뉴_해조류', '석식메뉴_장류', '석식메뉴_김치', '석식메뉴_만두',\n",
        "       '석식메뉴_곡물가루', '석식메뉴_과일', '석식메뉴_쌀', '석식메뉴_김밥_초밥', '석식메뉴_절임류', '석식메뉴_면류',\n",
        "       '석식메뉴_스튜', '석식메뉴_나물_무침류', '석식메뉴_피클', '석식메뉴_샐러드', '석식메뉴_우유', '석식메뉴_빵류',\n",
        "       '석식메뉴_음료', '석식메뉴_돼지고기', '석식메뉴_소고기', '석식메뉴_닭고기', '석식메뉴_오리고기']\n",
        "df.drop(columns=['조식', '중식', '석식'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAaGu6sRVOR1"
      },
      "source": [
        "### 외부 데이터 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU9m1cWDgN4R"
      },
      "source": [
        "dust_dir = os.path.join(path, '미세먼지_일별')\n",
        "wdata_dir = os.path.join(path, '날씨_시간별')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HgT1y52gZdD"
      },
      "source": [
        "w_attrs = ['강수', '기온', '습도', '강수형태']\n",
        "w_years = os.listdir(wdata_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH3kshIpgwwy"
      },
      "source": [
        "def get_wdata(data_path, dtype='num'):\n",
        "  datetime_list = []\n",
        "  value_list_12 = []\n",
        "  value_list_18 = []\n",
        "  curr_mon = ''\n",
        "\n",
        "  with open(data_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for i, line in enumerate(lines):\n",
        "      if line.strip() == '':\n",
        "        break\n",
        "      row_data = line.strip().split(',')\n",
        "      row_data = [elem.strip() for elem in row_data]\n",
        "      if i == 0:\n",
        "        curr_mon = row_data[-1].split()[-1][:-2]\n",
        "        continue\n",
        "      if len(row_data) == 1:\n",
        "        curr_mon = row_data[-1].split()[-1][:-2]\n",
        "        continue\n",
        "      r_day, r_hour, r_value = row_data\n",
        "      if r_hour in [\"1200\", \"1800\"]: # 점심 12시, 저녁 6시 기준으로 처리\n",
        "        if r_hour == \"1200\":\n",
        "          datetime_list.append(curr_mon[:4]+'-'+curr_mon[4:]+'-'+str('%02d'%int(r_day)))\n",
        "\n",
        "        if dtype == 'num':\n",
        "          if r_hour == \"1200\":\n",
        "            value_list_12.append(float(r_value))\n",
        "          else:\n",
        "            value_list_18.append(float(r_value))\n",
        "        else:\n",
        "          if r_hour == \"1200\":\n",
        "            value_list_12.append(str(round(float(r_value))))\n",
        "          else:\n",
        "            value_list_18.append(str(round(float(r_value))))\n",
        "          \n",
        "\n",
        "  return datetime_list, value_list_12, value_list_18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUoVNeu1gxs2"
      },
      "source": [
        "# 강수, 기온, 습도, 강수형태 데이터\n",
        "w_data_rain_12 = []\n",
        "w_data_temp_12 = []\n",
        "w_data_hum_12 = []\n",
        "w_data_rtype_12 = []\n",
        "w_data_rain_18 = []\n",
        "w_data_temp_18 = []\n",
        "w_data_hum_18 = []\n",
        "w_data_rtype_18 = []\n",
        "w_datetime = []\n",
        "\n",
        "for year in w_years:\n",
        "  w_subdir = os.path.join(wdata_dir, year)\n",
        "  file_names = os.listdir(w_subdir)\n",
        "  file_name = \"\"\n",
        "  if year != '2021':\n",
        "    file_name = f'{year}01_{year}12.csv'\n",
        "  else:\n",
        "    file_name = f'{year}01_{year}04.csv'\n",
        "  file_path_rain = os.path.join(w_subdir, '충무공동_강수_'+file_name)\n",
        "  file_path_temp = os.path.join(w_subdir, '충무공동_기온_'+file_name)\n",
        "  file_path_hum = os.path.join(w_subdir, '충무공동_습도_'+file_name)\n",
        "  file_path_rtype = os.path.join(w_subdir, '충무공동_강수형태_'+file_name)\n",
        "\n",
        "  datetime_list_rain, value_list_rain_12, value_list_rain_18 = get_wdata(file_path_rain, dtype='num') # 강수 데이터\n",
        "  datetime_list_temp, value_list_temp_12, value_list_temp_18 = get_wdata(file_path_temp, dtype='num') # 기온 데이터\n",
        "  datetime_list_hum, value_list_hum_12, value_list_hum_18 = get_wdata(file_path_hum, dtype='num') # 습도 데이터\n",
        "  datetime_list_rtype, value_list_rtype_12, value_list_rtype_18 = get_wdata(file_path_rtype, dtype='cat') # 강수형태 데이터\n",
        "  \n",
        "  w_datetime   += datetime_list_rain\n",
        "  w_data_rain_12  += value_list_rain_12\n",
        "  w_data_temp_12  += value_list_temp_12\n",
        "  w_data_hum_12   += value_list_hum_12\n",
        "  w_data_rtype_12 += value_list_rtype_12\n",
        "  w_data_rain_18  += value_list_rain_18\n",
        "  w_data_temp_18  += value_list_temp_18\n",
        "  w_data_hum_18   += value_list_hum_18\n",
        "  w_data_rtype_18 += value_list_rtype_18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsORoPLdgygT"
      },
      "source": [
        "w_df = pd.DataFrame({'일자':pd.Series(w_datetime, dtype='datetime64[ns]'),\n",
        "                   'rain_lunch':pd.Series(w_data_rain_12, dtype='float'),\n",
        "                   'temp_lunch':pd.Series(w_data_temp_12, dtype='float'),\n",
        "                   'hum_lunch':pd.Series(w_data_hum_12, dtype='float'),\n",
        "                   'rain_type_lunch':pd.Series(w_data_rtype_12, dtype='str'),\n",
        "                   'rain_dinner':pd.Series(w_data_rain_18, dtype='float'),\n",
        "                   'temp_dinner':pd.Series(w_data_temp_18, dtype='float'),\n",
        "                   'hum_dinner':pd.Series(w_data_hum_18, dtype='float'),\n",
        "                   'rain_type_dinner':pd.Series(w_data_rtype_18, dtype='str')})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBaSMJuAgzRj"
      },
      "source": [
        "# 불쾌지수 컬럼 추가\n",
        "# https://dacon.io/competitions/official/235736/codeshare/2753?page=1&dtype=recent\n",
        "w_df['discomfort_index_lunch'] = 1.8*w_df['temp_lunch'] - 0.55*(1-w_df['hum_lunch']/100)*(1.8*w_df['temp_lunch']-26) + 32\n",
        "w_df['discomfort_index_dinner'] = 1.8*w_df['temp_dinner'] - 0.55*(1-w_df['hum_dinner']/100)*(1.8*w_df['temp_dinner']-26) + 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiVnVyYfgz80"
      },
      "source": [
        "dust_file_paths = glob.glob(os.path.join(dust_dir, '*.xls'))\n",
        "d_datetime = []\n",
        "d_value1 = []\n",
        "d_value2 = []\n",
        "\n",
        "# 시간별 데이터의 경우 미세먼지 측정값 중 빈 값이 있는 경우가 어느 정도 있어서 배제했습니다.\n",
        "for file_path in dust_file_paths:\n",
        "  date_yyyymm = os.path.splitext(os.path.basename(file_path))[0] # yyyymm\n",
        "  date_year = date_yyyymm[:4]\n",
        "  date_mon = date_yyyymm[4:]\n",
        "  dust_df = None\n",
        "\n",
        "  if date_year == '2021':\n",
        "    dust_df = pd.read_excel(file_path, header=[0, 1], skiprows=3)\n",
        "  else:\n",
        "    dust_df = pd.read_excel(file_path, header=[0, 1])\n",
        "  cols = dust_df.columns\n",
        "  date_col = cols[0]\n",
        "  fine_dust_col = cols[1] # 미세먼지\n",
        "  ufine_dust_col = cols[2] # 초미세먼지\n",
        "\n",
        "  # 해당월의 일수 가져오기\n",
        "  days = calendar.monthrange(int(date_year),int(date_mon))[1] \n",
        "  for day in range(1, days+1):\n",
        "    day_1 = '%02d'%day\n",
        "    curr_day_df =  date_year+ '-' + date_mon + '-' + day_1\n",
        "\n",
        "    row_lunch = dust_df[dust_df[cols[0]] == curr_day_df]\n",
        "    row_dinner = dust_df[dust_df[cols[0]] == curr_day_df]\n",
        "    curr_date = date_year+'-'+date_mon+'-'+day_1\n",
        "  \n",
        "    d_datetime.append(curr_date)\n",
        "    d_value1.append(row_lunch[fine_dust_col].values[0])\n",
        "    d_value2.append(row_lunch[ufine_dust_col].values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE3Cg4eUg0kL"
      },
      "source": [
        "dust_df = pd.DataFrame({'일자':pd.Series(d_datetime, dtype='datetime64[ns]'),\n",
        "                   'fine_dust':pd.Series(d_value1, dtype='float'),\n",
        "                   'ultra_fine_dust':pd.Series(d_value2, dtype='float')})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vW5j6_Jg30z"
      },
      "source": [
        "df = pd.merge(df, dust_df, on='일자')\n",
        "df = pd.merge(df, w_df, on='일자')\n",
        "\n",
        "# 결측치 근처 관측치로 대체\n",
        "df['fine_dust'][564, 1129] = [36, 23]\n",
        "df['ultra_fine_dust'][234, 235, 564, 654, 1129] = [11, 31, 26, 5, 9]\n",
        "\n",
        "# 저녁 컬럼 삭제\n",
        "# df = df.drop(columns=['rain_dinner', 'temp_dinner', 'hum_dinner', 'rain_type_dinner', 'discomfort_index_dinner'])\n",
        "\n",
        "# 미세먼지 명목변수화\n",
        "df['fine_degree'] = df['fine_dust'].apply(lambda x : 0 if 0<=x<=30 else (1 if 31<=x<=80 else (2 if 81<=x<=150 else 3)))\n",
        "df['ultra_fine_degree'] = df['ultra_fine_dust'].apply(lambda x : 0 if 0<=x<=15 else (1 if 16<=x<=35 else (2 if 36<=x<=75 else 3)))\n",
        "df['fine_degree'] = df.apply(lambda x : max(x['fine_degree'], x['ultra_fine_degree']), axis=1)\n",
        "\n",
        "# 강수량 명목변수화\n",
        "df['rain_degree_lunch'] = df['rain_lunch'].apply(lambda x : 0 if x < 2 else 1)\n",
        "df['rain_degree_dinner'] = df['rain_dinner'].apply(lambda x : 0 if x < 2 else 1)\n",
        "\n",
        "# 불쾌지수 명목변수화 \n",
        "df['discomfort_degree_lunch'] = df['discomfort_index_lunch'].apply(lambda x : 0 if x<68 else (1 if 68<=x<75 else (2 if 75<=x<80 else 3)))\n",
        "df['discomfort_degree_dinner'] = df['discomfort_index_dinner'].apply(lambda x : 0 if x<68 else (1 if 68<=x<75 else (2 if 75<=x<80 else 3)))\n",
        "\n",
        "# 명목변수화하면서 삭제\n",
        "df = df.drop(columns=['rain_lunch', 'temp_lunch', 'hum_lunch', 'rain_type_lunch', 'discomfort_index_lunch',\n",
        "                      'rain_dinner', 'temp_dinner', 'hum_dinner', 'rain_type_dinner', 'discomfort_index_dinner',\n",
        "                      'fine_dust', 'ultra_fine_dust', 'ultra_fine_degree',])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3yZ6AQZV1sF"
      },
      "source": [
        "## 중간 변수 색출"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI10OVxAg7Zs"
      },
      "source": [
        "### 파생변수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP2g8FEBAuk3"
      },
      "source": [
        "path = '/content/drive/MyDrive/구내식당/water/'\n",
        "df = pd.read_csv(path+'df.csv')\n",
        "train = pd.read_csv(path+'train.csv')\n",
        "holiday = pd.read_csv(path+'holidays.csv', index_col=0)\n",
        "corona = pd.read_csv(path+'corona_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sbY-BF5UkhR"
      },
      "source": [
        "# 코로나 데이터 추가\n",
        "corona = corona.drop_duplicates(['일자'])\n",
        "check_corona = corona[['일자', '누적검사자']]\n",
        "\n",
        "df = pd.merge(df,corona[['일자', '일일검사자']], on='일자', how='left')\n",
        "df = df.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSUimT-mqos8"
      },
      "source": [
        "df['일자'] = df['일자'].astype('datetime64')\n",
        "corona['일자'] = corona['일자'].astype('datetime64')\n",
        "\n",
        "df['식사가능인원'] = df['정원']-(df['휴가자']+df['출장자'])+df['야근자']\n",
        "df['휴가출장'] = df['정원']-(df['휴가자']+df['출장자'])\n",
        "df['휴가출장재택'] = df['정원']-(df['휴가자']+df['출장자']+df['재택근무자'])\n",
        "df['휴가출장재택야근'] = df['정원']-(df['휴가자']+df['출장자']+df['재택근무자'])+df['야근자']\n",
        "df['휴가'] = df['정원']-(df['휴가자'])\n",
        "df['휴가야근'] = df['정원']-(df['휴가자'])+df['야근자']\n",
        "df['휴가재택야근'] = df['정원']-(df['휴가자']+df['재택근무자'])+df['야근자']\n",
        "df['휴가재택'] = df['정원']-(df['휴가자']+df['재택근무자'])\n",
        "# df['휴가비율'] = df['휴가자']/df['정원']\n",
        "# df['출장비율'] = df['출장자']/df['정원']\n",
        "# df['야근비율'] = df['야근자']/df['출근인원']\n",
        "# df['재택비율'] = df['재택근무자']/df['정원']\n",
        "df['휴가_출장'] = df['휴가자']+df['출장자']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypl9PQCTcB_k"
      },
      "source": [
        "df['년'] = df['일자'].dt.year\n",
        "df['월'] = df['일자'].dt.month\n",
        "df['년월'] = df['년'].astype('str')+'_'+df['월'].astype('str')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXHv86fOeRK_"
      },
      "source": [
        "first_dayofmonth = []\n",
        "last_dayofmonth = []\n",
        "for i in df['년월'].unique() :\n",
        "    first_dayofmonth.append(df[df['년월']==i].iloc[0].name)\n",
        "    last_dayofmonth.append(df[df['년월']==i].iloc[-1].name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YcKlMbchrdQ"
      },
      "source": [
        "df['첫_출근일'] = df.apply(lambda x : 1 if x.name in first_dayofmonth else 0, axis=1)\n",
        "df['마지막_출근일'] = df.apply(lambda x : 1 if x.name in last_dayofmonth else 0, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXGaalWVnygH"
      },
      "source": [
        "df['년'] = df['일자'].dt.year\n",
        "df['월'] = df['일자'].dt.month\n",
        "df['일'] = df['일자'].dt.day\n",
        "month_to_season = {1: 3,2: 3,3:0,4:0,5:0,6:1,7:1,8:1,9:2,10:2,11:2,12: 3}\n",
        "df['계절'] = df['월'].apply(lambda x : month_to_season[x])\n",
        "\n",
        "df['요일'] = df['일자'].dt.weekday\n",
        "df['is_monday'] = df['요일'].apply(lambda x : 1 if (x==0) else 0) \n",
        "df['야근_가능'] = df['요일'].apply(lambda x : 1 if (x=='수') or (x=='금') else 0)\n",
        "df['정책_변화'] = df['일자'].apply(lambda x : 0 if x < pd.to_datetime('2019-01-04') else 1)\n",
        "\n",
        "df['연기준몇주째']= df['일자'].dt.weekofyear\n",
        "df['월마지막일여부'] =df['일자'].dt.is_month_end\n",
        "\n",
        "train = df.iloc[:train.shape[0], :]\n",
        "test = df.iloc[train.shape[0]:, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUOcg-fSibZ_"
      },
      "source": [
        "import pendulum\n",
        "train['주차'] = train['일자'].apply(lambda x: pendulum.parse(str(x)).week_of_month)\n",
        "test['주차'] = test['일자'].apply(lambda x: pendulum.parse(str(x)).week_of_month)\n",
        "\n",
        "repair_2017 = train[(train['년']==2017)&(train['주차']<0)]['일자'].dt.week\n",
        "repair_2021 = train[(train['년']==2021)&(train['주차']<0)]['일자'].dt.week\n",
        "test_repair = test[(test['년']==2021)&(test['주차']<0)]['일자'].dt.week\n",
        "\n",
        "train['주차'][list(repair_2017.index)] = repair_2017.values\n",
        "train['주차'][list(repair_2021.index)] = repair_2021.values\n",
        "test['주차'][list(test_repair.index)] = test_repair.values\n",
        "train['주차'][list(train[train['주차']==-46].index)] = np.array([6, 6, 6])\n",
        "\n",
        "df = pd.concat([train, test])\n",
        "df['월_주차'] = df['년'].astype('str')+'_'+df['월'].astype('str')+'_'+df['주차'].astype('str')\n",
        "\n",
        "train = df.iloc[:train.shape[0], :]\n",
        "test = df.iloc[train.shape[0]:, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LJmwcVU854d"
      },
      "source": [
        "df['is_corona'] = df['일자'].apply(lambda x : 0 if x < pd.to_datetime('2020-01-06') else 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0PpA641VFuy"
      },
      "source": [
        "# 공휴일 데이터 추가\n",
        "holiday['date'] = pd.to_datetime(holiday['date'])\n",
        "df['일자'] = pd.to_datetime(df['일자'])\n",
        "df['before_holiday'] = df['일자'].apply(lambda x : 1 if (x+dt.timedelta(1) in holiday['date'].tolist()) else 0)\n",
        "df['after_holiday'] = df['일자'].apply(lambda x : 1 if (x-dt.timedelta(1) in holiday['date'].tolist()) else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n67gXH9HUkz1"
      },
      "source": [
        "# # 이벤트 데이터 고민 - 복날 / 연말\n",
        "event = pd.to_datetime(['2016-08-16', '2016-07-27', '2016-07-18', '2017-08-11', '2017-07-21','2017-07-12', '2018-08-16', '2018-07-27', '2018-07-17', '2019-08-12', '2019-07-22', '2019-07-12', '2020-07-27', '2020-07-16'])\n",
        "df['복날'] = df['일자'].apply(lambda x : 1 if x in event else 0)\n",
        "\n",
        "# end_year = df[(df['월']==12)&(df['일']>=21)].index\n",
        "# df['연말'] = df.apply(lambda x : 1 if  x.name in end_year else 0, axis=1)\n",
        "\n",
        "# 명절 전 영업일 여부 + 복날\n",
        "event = pd.to_datetime(['2016-02-05', '2019-09-13', '2017-01-26','2017-09-29', '2018-02-14', '2018-09-21', '2019-02-01', '2019-09-11', '2020-01-23', '2020-09-30', '2021-02-10'])\n",
        "df['명절_이전_영업일'] = df['일자'].apply(lambda x : 1 if x in event else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrSpxZ3FiFYR"
      },
      "source": [
        "df['휴식기간'] = df['일자'].diff().dt.days.fillna(0).astype('int')\n",
        "df['휴식기간'] = df['휴식기간'].apply(lambda x: 1 if x>=4 else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOOzgdwoaWgD"
      },
      "source": [
        "# 인원 변화가 생긴 주에 중식계, 석식계가 많은가 했는데 그렇지 않았다.\n",
        "df['인원변화'] = df['정원'].diff()\n",
        "df['인원변화'][0] = 0\n",
        "df['변화'] = df['인원변화'].apply(lambda x : 2 if x>10 else (1 if -10<=x<=10 else 0))\n",
        "\n",
        "display(df[df.index.isin(df[df['변화']==0].index-1)][['중식계', '석식계']].mean())\n",
        "display(df[~df.index.isin(df[df['변화']==0].index-1)][['중식계', '석식계']].mean())\n",
        "\n",
        "df['출장자제외'] = df['정원'] - df['출장자']\n",
        "df['재택근무제외'] = df['정원'] - df['재택근무자']\n",
        "df['연기준몇일째']= df['일자'].dt.dayofyear\n",
        "df['연기준몇주째']= df['일자'].dt.weekofyear\n",
        "df['월일수']= df['일자'].dt.days_in_month\n",
        "df['윤년여부'] = df['일자'].dt.is_leap_year\n",
        "df['월시작일여부'] = df['일자'].dt.is_month_start\n",
        "df['월마지막일여부'] =df['일자'].dt.is_month_end\n",
        "df['분기시작일여부'] =df['일자'].dt.is_quarter_start\n",
        "df['분기마지막일여부'] =df['일자'].dt.is_quarter_end\n",
        "df['연시작일여부'] =df['일자'].dt.is_year_start\n",
        "df['연마지막일여부'] =df['일자'].dt.is_year_end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7whoF48rOKX"
      },
      "source": [
        "### 데이터 정규화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE6cH0Pm5a-t"
      },
      "source": [
        "def get_one_hot(x, target_val):\n",
        "  if x == target_val:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EDdvFp75bwl"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "onehot_col = ['년', '월', '요일', '계절']\n",
        "df_tmp = df.copy()\n",
        "# df = pd.concat([df[list((set(df.columns)-set(onehot_col)))],\\\n",
        "#                 pd.get_dummies(df[onehot_col])], axis=1)\n",
        "\n",
        "sub_types = [[2016, 2017, 2018, 2019, 2020, 2021], [1,2,3,4,5,6,7,8,9,10,11,12], [0,1,2,3,4], [0,1,2,3]]\n",
        "\n",
        "for i, col_type in enumerate(onehot_col):\n",
        "  for j, class_nm in enumerate(sub_types[i]):\n",
        "    df_tmp[col_type + '_' + str(class_nm)] = df_tmp[col_type].apply(lambda x: get_one_hot(x, class_nm))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEB8BCiYjiwa"
      },
      "source": [
        "# df[['년', '월']] = df[['년', '월']].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZD0jbO5k8-z"
      },
      "source": [
        "# df.drop(columns=['정원', '휴가자', '출장자', '야근자', '년월'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvixMcvWUJsp"
      },
      "source": [
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# # lbe = LabelEncoder()\n",
        "# # df[['년']] = lbe.fit_transform(df[['년']])\n",
        "# onehot_col = ['년', '월','요일', '계절']\n",
        "# df = pd.concat([df[list((set(df.columns)-set(onehot_col)))],\\\n",
        "#                 pd.get_dummies(df[onehot_col])], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7Y14JTTgb0K"
      },
      "source": [
        "gukgam = pd.to_datetime(['2016-10-04', '2016-10-05', '2016-10-06', '2016-10-07', '2017-10-10', '2017-10-11', '2017-10-12', '2017-10-13', '2018-10-08', '2018-10-10', '2018-10-11',\\\n",
        "          '2018-10-12', '2019-10-02', '2019-10-04', '2020-10-05', '2020-10-06', '2020-10-07', '2020-10-08'])\n",
        "# gukgam = ['2019-10-04', '2019-10-02', '2018-10-10']\n",
        "df_tmp['국정감사'] = df_tmp['일자'].apply(lambda x : 1 if x in gukgam else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOtRSrMpGVer"
      },
      "source": [
        "# train = df.iloc[:train.shape[0], :]\n",
        "# test = df.iloc[train.shape[0]:, :]\n",
        "\n",
        "train = df_tmp.iloc[:train.shape[0], :]\n",
        "test = df_tmp.iloc[train.shape[0]:, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF7tty1F6EJo"
      },
      "source": [
        "train = train.drop(columns=['일자','월_주차', '정원', '년', '월', '요일',  '계절'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHu0xoJwCOPj"
      },
      "source": [
        "train[['월마지막일여부', '윤년여부', '월시작일여부', '분기시작일여부', '분기마지막일여부','연시작일여부', '연마지막일여부']] = train[['월마지막일여부', '윤년여부', '월시작일여부', '분기시작일여부', '분기마지막일여부', '연시작일여부', '연마지막일여부']].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DULPkPSaGoYX"
      },
      "source": [
        "train_1 =train[[i for i in train.columns if ('석식' not in i) and ('dinner' not in i)]]\n",
        "train_2 =train[[i for i in train.columns if ('중식' not in i) and ('lunch' not in i)]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYnxhThaC3QF"
      },
      "source": [
        "## AutoML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHTKx9y56jgj"
      },
      "source": [
        "# 이상치 제거\n",
        "train_2 = train_2.loc[train_2['석식계'] != 0.0]\n",
        "train_2 = train_2.loc[(train_2['년_2016'] != 1) | (train_2['월_10'] != 1) | (train_2['일'] != 5)]\n",
        "train_2 = train_2.loc[(train_2['년_2019'] != 1) | (train_2['월_9'] != 1) | (train_2['일'] != 11)]\n",
        "train_2 = train_2.loc[(train_2['년_2019'] != 1) | (train_2['월_12'] != 1) | (train_2['일'] != 23)]\n",
        "train_2 = train_2.loc[(train_2['년_2019'] != 1) | (train_2['월_12'] != 1) | (train_2['일'] != 30)]\n",
        "train_2 = train_2.loc[(train_2['년_2020'] != 1) | (train_2['월_1'] != 1) | (train_2['일'] != 23)]\n",
        "\n",
        "train_1 = train_1.loc[(train_1['년_2016'] != 1) | (train_1['월_10'] != 1) | (train_1['일'] != 5)]\n",
        "train_1 = train_1.loc[(train_1['년_2017'] != 1) | (train_1['월_12'] != 1) | (train_1['일'] != 28)]\n",
        "train_1 = train_1.loc[(train_1['년_2020'] != 1) | (train_1['월_12'] != 1) | (train_1['일'] != 2)]\n",
        "train_1 = train_1.loc[(train_1['년_2018'] != 1) | (train_1['월_9'] != 1) | (train_1['일'] != 14)]\n",
        "train_1 = train_1.loc[(train_1['년_2018'] != 1) | (train_1['월_12'] != 1) | (train_1['일'] != 24)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVXKBBoIMTUN"
      },
      "source": [
        "temp_list = [ '년_2016',\n",
        " '년_2017',\n",
        " '년_2018',\n",
        " '년_2019',\n",
        " '년_2020',\n",
        " '년_2021',\n",
        " '월_1',\n",
        " '월_2',\n",
        " '월_3',\n",
        " '월_4',\n",
        " '월_5',\n",
        " '월_6',\n",
        " '월_7',\n",
        " '월_8',\n",
        " '월_9',\n",
        " '월_10',\n",
        " '월_11',\n",
        " '월_12',\n",
        " '요일_0',\n",
        " '요일_1',\n",
        " '요일_2',\n",
        " '요일_3',\n",
        " '요일_4',\n",
        " 'is_corona',\n",
        " 'fine_degree',\n",
        " 'rain_degree_lunch',\n",
        " 'discomfort_degree_lunch',\n",
        " '일',\n",
        " '식사가능인원',\n",
        " '재택근무자',\n",
        " '출장자',\n",
        " '휴가자',\n",
        " 'after_holiday',\n",
        " '연기준몇주째',\n",
        " '월일수',\n",
        " '국정감사',\n",
        "#   '중식메뉴_육류', '중식메뉴_난류', '중식메뉴_덮밥_국밥류', '중식메뉴_비빔밥_볶음밥류', '중식메뉴_국탕류', '중식메뉴_구이류', '중식메뉴_전류',\n",
        "#    '중식메뉴_튀김류', '중식메뉴_콩류', '중식메뉴_묵', '중식메뉴_생선_조개류', '중식메뉴_채소류', '중식메뉴_해조류', '중식메뉴_장류', '중식메뉴_만두', '중식메뉴_곡물가루', '중식메뉴_과일', \n",
        "#   '중식메뉴_김밥_초밥', '중식메뉴_절임류', '중식메뉴_면류', '중식메뉴_스튜', '중식메뉴_샐러드', '중식메뉴_우유', '중식메뉴_빵류', '중식메뉴_돼지고기', '중식메뉴_소고기', '중식메뉴_닭고기', '중식메뉴_오리고기',\n",
        "#  'is_monday',\n",
        "#   '중식메뉴_육류',\n",
        "#  '중식메뉴_난류',\n",
        "#  '중식메뉴_죽류',\n",
        "#  '중식메뉴_덮밥_국밥류',\n",
        "#  '중식메뉴_비빔밥_볶음밥류',\n",
        "#  '중식메뉴_국탕류',\n",
        "#  '중식메뉴_구이류',\n",
        "#  '중식메뉴_전류',\n",
        "#  '중식메뉴_튀김류',\n",
        "#  '중식메뉴_곡물',\n",
        "#  '중식메뉴_콩류',\n",
        "#  '중식메뉴_묵',\n",
        "#  '중식메뉴_생선_조개류',\n",
        "#  '중식메뉴_채소류',\n",
        "#  '중식메뉴_해조류',\n",
        "#  '중식메뉴_장류',\n",
        "#  '중식메뉴_김치',\n",
        "#  '중식메뉴_만두',\n",
        "#  '중식메뉴_곡물가루',\n",
        "#  '중식메뉴_과일',\n",
        "#  '중식메뉴_쌀',\n",
        "#  '중식메뉴_김밥_초밥',\n",
        "#  '중식메뉴_절임류',\n",
        "#  '중식메뉴_면류',\n",
        "#  '중식메뉴_스튜',\n",
        "#  '중식메뉴_나물_무침류',\n",
        "#  '중식메뉴_피클',\n",
        "#  '중식메뉴_샐러드',\n",
        "#  '중식메뉴_우유',\n",
        "#  '중식메뉴_빵류',\n",
        "#  '중식메뉴_음료',\n",
        "#  '중식메뉴_돼지고기',\n",
        "#  '중식메뉴_소고기',\n",
        "#  '중식메뉴_닭고기',\n",
        "#  '중식메뉴_오리고기',\n",
        "#  '주차'\n",
        "#  '변화', '인원변화', '휴식기간', '명절_이전_영업일','복날',\n",
        "#  'before_holiday', '주차', '정책_변화',\n",
        "#  , '야근_가능' '일일검사자','첫_출근일',\n",
        "#  '마지막_출근일',\n",
        " ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPFuaA6lQuNo"
      },
      "source": [
        "* 의미가 큰 변수  \n",
        "    * 날씨, 일, \n",
        "    * 식사가능인원 / 재택근무자 / 출장자 / 휴가자\n",
        "    * 휴일 다음날 \n",
        "* 의미가 없는 것\n",
        "    * 계절, 첫_출근일, 마지막_출근일\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmB191p8pYCH"
      },
      "source": [
        "* 60.6889"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JARYWbqt6jvM"
      },
      "source": [
        "automl = AutoML()\n",
        "\n",
        "y_train = train_1['중식계']\n",
        "X_train = train_1[['휴가자', '출장자', '야근자', '재택근무자', '중식메뉴_육류', '중식메뉴_난류', '중식메뉴_덮밥_국밥류', '중식메뉴_비빔밥_볶음밥류', '중식메뉴_국탕류', '중식메뉴_구이류', '중식메뉴_전류', '중식메뉴_튀김류', '중식메뉴_콩류', '중식메뉴_묵', '중식메뉴_생선_조개류', '중식메뉴_채소류', '중식메뉴_해조류', '중식메뉴_장류', '중식메뉴_만두', '중식메뉴_곡물가루', '중식메뉴_과일', '중식메뉴_김밥_초밥', '중식메뉴_절임류', '중식메뉴_면류', '중식메뉴_스튜', '중식메뉴_샐러드', '중식메뉴_우유', '중식메뉴_빵류', '중식메뉴_돼지고기', '중식메뉴_소고기', '중식메뉴_닭고기', '중식메뉴_오리고기', '식사가능인원', '일', '야근_가능', '연기준몇주째', '월마지막일여부', '주차', 'is_corona', 'fine_degree', 'rain_degree_lunch', 'discomfort_degree_lunch', 'before_holiday', 'after_holiday', '년_2016', '년_2017', '년_2018', '년_2019', '년_2020', '년_2021', '월_1', '월_2', '월_3', '월_4', '월_5', '월_6', '월_7', '월_8', '월_9', '월_10', '월_11', '월_12', '요일_0', '요일_1', '요일_2', '요일_3', '요일_4', '계절_0', '계절_1', '계절_2', '계절_3']]\n",
        "# Specify automl goal and constraint\n",
        "automl_settings = {\n",
        "    \"time_budget\": 120,  # in seconds\n",
        "    \"metric\": 'mae',\n",
        "    \"task\": 'regression'\n",
        "}\n",
        "# Train with labeled input data\n",
        "automl.fit(X_train=X_train, y_train=y_train,\n",
        "           **automl_settings)\n",
        "# Predict\n",
        "# print(automl.predict(X_train))\n",
        "# Export the best model\n",
        "print(automl.model) # 62.8802\n",
        "# 61.8124 - 이상치 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rqhMdnC7qD4"
      },
      "source": [
        "X_test = test[list(X_train.columns)]\n",
        "pred1 = automl.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZds91xTQGOh"
      },
      "source": [
        "list(train_2.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpXPbkw8U0JN"
      },
      "source": [
        "* 42.8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnWzBMKRQR4r"
      },
      "source": [
        "temp_din = [ '년_2016',\n",
        " '년_2017',\n",
        " '년_2018',\n",
        " '년_2019',\n",
        " '년_2020',\n",
        " '년_2021',\n",
        " '월_1',\n",
        " '월_2',\n",
        " '월_3',\n",
        " '월_4',\n",
        " '월_5',\n",
        " '월_6',\n",
        " '월_7',\n",
        " '월_8',\n",
        " '월_9',\n",
        " '월_10',\n",
        " '월_11',\n",
        " '월_12',\n",
        " '요일_0',\n",
        " '요일_1',\n",
        " '요일_2',\n",
        " '요일_3',\n",
        " '요일_4',\n",
        "  '일',\n",
        " '식사가능인원',\n",
        " '휴가자',\n",
        " '야근자',\n",
        " '출장자',\n",
        " 'is_corona',\n",
        " '명절_이전_영업일',\n",
        " '휴식기간',\n",
        "  '계절_0',\n",
        " '계절_1',\n",
        " '계절_2',\n",
        " '계절_3',\n",
        "#  '국정감사',\n",
        "#  '월일수',\n",
        "#  '변화',\n",
        "#  'before_holiday',\n",
        "# 'after_holiday',\n",
        "#  '연기준몇주째',\n",
        "#  '야근_가능',\n",
        "#  '첫_출근일',\n",
        "#  '마지막_출근일',\n",
        "#  '재택근무자'\n",
        "#    '일일검사자',\n",
        "#    'fine_degree',\n",
        "#  'rain_degree_dinner',\n",
        "#  'discomfort_degree_dinner',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zicAX8FQHz_"
      },
      "source": [
        "automl = AutoML()\n",
        "y_train = train_2['석식계']\n",
        "X_train = train_2[['휴가자', '출장자', '야근자', '재택근무자', '석식메뉴_육류', '석식메뉴_난류', '석식메뉴_덮밥_국밥류', '석식메뉴_비빔밥_볶음밥류', '석식메뉴_국탕류', '석식메뉴_구이류', '석식메뉴_전류', '석식메뉴_튀김류', '석식메뉴_콩류', '석식메뉴_묵', '석식메뉴_생선_조개류', '석식메뉴_채소류', '석식메뉴_해조류', '석식메뉴_장류', '석식메뉴_만두', '석식메뉴_곡물가루', '석식메뉴_과일', '석식메뉴_김밥_초밥', '석식메뉴_절임류', '석식메뉴_면류', '석식메뉴_스튜', '석식메뉴_샐러드', '석식메뉴_우유', '석식메뉴_빵류', '석식메뉴_돼지고기', '석식메뉴_소고기', '석식메뉴_닭고기', '석식메뉴_오리고기', '식사가능인원', '일', '야근_가능', '연기준몇주째', '월마지막일여부', '주차', 'is_corona', 'fine_degree', 'rain_degree_dinner', 'discomfort_degree_dinner', 'before_holiday', 'after_holiday', '명절_이전_영업일', '년_2016', '년_2017', '년_2018', '년_2019', '년_2020', '년_2021', '월_1', '월_2', '월_3', '월_4', '월_5', '월_6', '월_7', '월_8', '월_9', '월_10', '월_11', '월_12', '요일_0', '요일_1', '요일_2', '요일_3', '요일_4', '계절_0', '계절_1', '계절_2', '계절_3']]\n",
        "# Specify automl goal and constraint\n",
        "automl_settings = {\n",
        "    \"time_budget\": 120,  # in seconds\n",
        "    \"metric\": 'mae',\n",
        "    \"task\": 'regression'\n",
        "}\n",
        "# Train with labeled input data\n",
        "automl.fit(X_train=X_train, y_train=y_train,\n",
        "           **automl_settings)\n",
        "# Predict\n",
        "# print(automl.predict(X_train))\n",
        "# Export the best model\n",
        "print(automl.model) # 44.7386\n",
        "# 43.4131 - 명절 전 영업일 추가\n",
        "# 42.7798 - 명절 전 영업일 추가, 이상치 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROw30rGRQKdm"
      },
      "source": [
        "X_test = test[list(X_train.columns)]\n",
        "pred2 = automl.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jt2ARcrQLdU"
      },
      "source": [
        "sample_submission = pd.read_csv(path+'sample_submission.csv')\n",
        "submission = sample_submission.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgN_9TE0QML8"
      },
      "source": [
        "submission['중식계'] = pred1\n",
        "submission['석식계'] = pred2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ej4FbP7QNXF"
      },
      "source": [
        "from datetime import datetime\n",
        "now_tm = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')\n",
        "\n",
        "sub_path = '/content/drive/MyDrive/DACON/Dacon_Industry_Meal/submit/'\n",
        "submission.to_csv(sub_path+now_tm+'.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE_WTj5OCvsW"
      },
      "source": [
        "## Pycaret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9H957l5l16L"
      },
      "source": [
        "feature_selection - 전진 단계별 선택법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5lUYMDml50w"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "## 전진 단계별 선택법 - 중식\n",
        "lunch_cols = train_1.columns.tolist()\n",
        "lunch_cols.remove('중식계')\n",
        "lunch_cols.remove('일자')\n",
        "variables = lunch_cols ## 설명 변수 리스트\n",
        " \n",
        "y = train_1['중식계'] ## 반응 변수\n",
        "selected_variables = [] ## 선택된 변수들\n",
        "sl_enter = 0.05\n",
        "sl_remove = 0.05\n",
        " \n",
        "sv_per_step = [] ## 각 스텝별로 선택된 변수들\n",
        "adjusted_r_squared = [] ## 각 스텝별 수정된 결정계수\n",
        "steps = [] ## 스텝\n",
        "step = 0\n",
        "while len(variables) > 0:\n",
        "    remainder = list(set(variables) - set(selected_variables))\n",
        "    pval = pd.Series(index=remainder) ## 변수의 p-value\n",
        "    ## 기존에 포함된 변수와 새로운 변수 하나씩 돌아가면서 \n",
        "    ## 선형 모형을 적합한다.\n",
        "    for col in remainder: \n",
        "        X = train_1[selected_variables+[col]]\n",
        "        X = sm.add_constant(X)\n",
        "        model = sm.OLS(y,X).fit()\n",
        "\n",
        "        pval[col] = model.pvalues[col]\n",
        " \n",
        "    min_pval = pval.min()\n",
        "    if min_pval < sl_enter: ## 최소 p-value 값이 기준 값보다 작으면 포함\n",
        "        selected_variables.append(pval.idxmin())\n",
        "        ## 선택된 변수들에대해서\n",
        "        ## 어떤 변수를 제거할지 고른다.\n",
        "        while len(selected_variables) > 0:\n",
        "            selected_X = train_1[selected_variables]\n",
        "            selected_X = sm.add_constant(selected_X)\n",
        "            selected_pval = sm.OLS(y,selected_X).fit().pvalues[1:] ## 절편항의 p-value는 뺀다\n",
        "            max_pval = selected_pval.max()\n",
        "            if max_pval >= sl_remove: ## 최대 p-value값이 기준값보다 크거나 같으면 제외\n",
        "                remove_variable = selected_pval.idxmax()\n",
        "                selected_variables.remove(remove_variable)\n",
        "            else:\n",
        "                break\n",
        "        \n",
        "        step += 1\n",
        "        steps.append(step)\n",
        "        adj_r_squared = sm.OLS(y,sm.add_constant(train_1[selected_variables])).fit().rsquared_adj\n",
        "        adjusted_r_squared.append(adj_r_squared)\n",
        "        sv_per_step.append(selected_variables.copy())\n",
        "    else:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7FQXO5kl6HA"
      },
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "fig.set_facecolor('white')\n",
        " \n",
        "font_size = 15\n",
        "plt.xticks(steps,[f'step {s}\\n'+'\\n'.join(sv_per_step[i]) for i,s in enumerate(steps)], fontsize=12)\n",
        "plt.plot(steps, adjusted_r_squared, marker='o')\n",
        "    \n",
        "plt.ylabel('Adjusted R Squared',fontsize=font_size)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJP7mDNAl6KH"
      },
      "source": [
        "train_1_tmp = train_1[selected_variables]\n",
        "train_1_tmp['중식계'] = train_1['중식계']\n",
        "train_1 = train_1_tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWqcYAsjl6OC"
      },
      "source": [
        "## 전진 단계별 선택법 - 석식\n",
        "dinner_cols = train_2.columns.tolist()\n",
        "dinner_cols.remove('석식계')\n",
        "dinner_cols.remove('일자')\n",
        "variables = dinner_cols ## 설명 변수 리스트\n",
        " \n",
        "y = train_2['석식계'] ## 반응 변수\n",
        "selected_variables_dinner = [] ## 선택된 변수들\n",
        "sl_enter = 0.05\n",
        "sl_remove = 0.05\n",
        " \n",
        "sv_per_step = [] ## 각 스텝별로 선택된 변수들\n",
        "adjusted_r_squared = [] ## 각 스텝별 수정된 결정계수\n",
        "steps = [] ## 스텝\n",
        "step = 0\n",
        "while len(variables) > 0:\n",
        "    remainder = list(set(variables) - set(selected_variables_dinner))\n",
        "    pval = pd.Series(index=remainder) ## 변수의 p-value\n",
        "    ## 기존에 포함된 변수와 새로운 변수 하나씩 돌아가면서 \n",
        "    ## 선형 모형을 적합한다.\n",
        "    for col in remainder: \n",
        "        X = train_2[selected_variables_dinner+[col]]\n",
        "        X = sm.add_constant(X)\n",
        "        model = sm.OLS(y,X).fit()\n",
        "\n",
        "        pval[col] = model.pvalues[col]\n",
        " \n",
        "    min_pval = pval.min()\n",
        "    if min_pval < sl_enter: ## 최소 p-value 값이 기준 값보다 작으면 포함\n",
        "        selected_variables_dinner.append(pval.idxmin())\n",
        "        ## 선택된 변수들에대해서\n",
        "        ## 어떤 변수를 제거할지 고른다.\n",
        "        while len(selected_variables_dinner) > 0:\n",
        "            selected_X = train_2[selected_variables_dinner]\n",
        "            selected_X = sm.add_constant(selected_X)\n",
        "            selected_pval = sm.OLS(y,selected_X).fit().pvalues[1:] ## 절편항의 p-value는 뺀다\n",
        "            max_pval = selected_pval.max()\n",
        "            if max_pval >= sl_remove: ## 최대 p-value값이 기준값보다 크거나 같으면 제외\n",
        "                remove_variable = selected_pval.idxmax()\n",
        "                selected_variables_dinner.remove(remove_variable)\n",
        "            else:\n",
        "                break\n",
        "        \n",
        "        step += 1\n",
        "        steps.append(step)\n",
        "        adj_r_squared = sm.OLS(y,sm.add_constant(train_2[selected_variables_dinner])).fit().rsquared_adj\n",
        "        adjusted_r_squared.append(adj_r_squared)\n",
        "        sv_per_step.append(selected_variables_dinner.copy())\n",
        "    else:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc4NgqVEl-wE"
      },
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "fig.set_facecolor('white')\n",
        " \n",
        "font_size = 15\n",
        "plt.xticks(steps,[f'step {s}\\n'+'\\n'.join(sv_per_step[i]) for i,s in enumerate(steps)], fontsize=12)\n",
        "plt.plot(steps, adjusted_r_squared, marker='o')\n",
        "    \n",
        "plt.ylabel('Adjusted R Squared',fontsize=font_size)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P4WL--4mAbw"
      },
      "source": [
        "train_2_tmp = train_2[selected_variables_dinner]\n",
        "train_2_tmp['석식계'] = train_2['석식계']\n",
        "train_2 = train_2_tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh5eAD5nmBud"
      },
      "source": [
        "# test 데이터\n",
        "cols_lunch = selected_variables\n",
        "cols_dinner = selected_variables_dinner\n",
        "test_lunch = test[cols_lunch]\n",
        "test_dinner = test[cols_dinner]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLHhl6zpTxUy"
      },
      "source": [
        "reg = setup(data=train_1,\n",
        "            target='중식계',\n",
        "            numeric_imputation = 'mean',\n",
        "            normalize = True,\n",
        "            silent= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDOqdaKWT6xm"
      },
      "source": [
        "best_5 = compare_models(sort='MAE', n_select=5)\n",
        "blended = blend_models(estimator_list= best_5, fold=5, optimize='MAE')\n",
        "pred_holdout = predict_model(blended)\n",
        "final_model = finalize_model(blended)\n",
        "pred1 = predict_model(final_model, test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCdlhjgnU39F"
      },
      "source": [
        "sample_submission = pd.read_csv(path+'sample_submission.csv')\n",
        "submission = sample_submission.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1fj6sjNVInL"
      },
      "source": [
        "submission['중식계'] = pred1.reset_index()['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KblKSlEIUTm"
      },
      "source": [
        "reg = setup(data=train_2,\n",
        "            target='석식계',\n",
        "            numeric_imputation = 'mean',\n",
        "            normalize = True,\n",
        "            silent= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y42zsb9KIXPE"
      },
      "source": [
        "best_5 = compare_models(sort='MAE', n_select=5)\n",
        "blended = blend_models(estimator_list= best_5, fold=5, optimize='MAE')\n",
        "pred_holdout = predict_model(blended)\n",
        "final_model = finalize_model(blended)\n",
        "pred2 = predict_model(final_model, test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPmlmWLBIXGG"
      },
      "source": [
        "submission['석식계'] = pred2.reset_index()['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFfBt8X5VKNr"
      },
      "source": [
        "sub_path = '/content/drive/MyDrive/DACON/Dacon_Industry_Meal/submit/'\n",
        "best_submit = pd.read_csv(sub_path+'20210605_01_79.csv')\n",
        "df_82 = pd.read_csv(sub_path+'20210608_01_holiday_82.csv')\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "def show_mae(data) : \n",
        "    result = mean_absolute_error(best_submit['중식계'], data['중식계'])+mean_absolute_error(best_submit['석식계'], data['석식계'])\n",
        "    return display(result)\n",
        "\n",
        "show_mae(submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-RXYMOBZA3O"
      },
      "source": [
        "submission.to_csv(sub_path+'/20210619_02.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}